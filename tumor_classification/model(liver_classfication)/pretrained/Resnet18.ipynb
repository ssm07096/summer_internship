{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import nibabel as nib\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchsummary\n",
    "from torchvision import transforms, models\n",
    "import time\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일이름 sort해서 list저장\n",
    "data_path='/disk1/data_liverbound_noclip/'\n",
    "name_list=os.listdir(data_path)\n",
    "\n",
    "segmentation_data = [files[:-4] for files in name_list if files.startswith('segmentation')]\n",
    "segmentation_data=list(set(segmentation_data))\n",
    "segmentation_data.sort()\n",
    "seg_data_test=[]\n",
    "for i in range(30,45):\n",
    "    seg_data_test.append(segmentation_data.pop(i))\n",
    "\n",
    "volume_data=[files[:-4] for files in name_list if files.startswith('volume')]\n",
    "volume_data=list(set(volume_data))\n",
    "volume_data.sort()\n",
    "vol_data_test=[]\n",
    "for i in range(30,45):\n",
    "    vol_data_test.append(volume_data.pop(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_labels=np.loadtxt('/home/sumins/workspace/liver_classification/all_labels.txt',dtype=int)\n",
    "# all_labels=all_labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmentation-0\n",
      "segmentation-1\n",
      "segmentation-10\n",
      "segmentation-100\n",
      "segmentation-101\n",
      "segmentation-102\n",
      "segmentation-103\n",
      "segmentation-104\n",
      "segmentation-105\n",
      "segmentation-106\n",
      "segmentation-107\n",
      "segmentation-108\n",
      "segmentation-109\n",
      "segmentation-11\n",
      "segmentation-110\n",
      "segmentation-111\n",
      "segmentation-112\n",
      "segmentation-113\n",
      "segmentation-114\n",
      "segmentation-115\n",
      "segmentation-116\n",
      "segmentation-117\n",
      "segmentation-118\n",
      "segmentation-119\n",
      "segmentation-12\n",
      "segmentation-120\n",
      "segmentation-121\n",
      "segmentation-122\n",
      "segmentation-123\n",
      "segmentation-124\n",
      "segmentation-126\n",
      "segmentation-128\n",
      "segmentation-13\n",
      "segmentation-15\n",
      "segmentation-17\n",
      "segmentation-19\n",
      "segmentation-20\n",
      "segmentation-22\n",
      "segmentation-24\n",
      "segmentation-26\n",
      "segmentation-28\n",
      "segmentation-3\n",
      "segmentation-31\n",
      "segmentation-33\n",
      "segmentation-35\n",
      "segmentation-36\n",
      "segmentation-37\n",
      "segmentation-38\n",
      "segmentation-39\n",
      "segmentation-4\n",
      "segmentation-40\n",
      "segmentation-41\n",
      "segmentation-42\n",
      "segmentation-43\n",
      "segmentation-44\n",
      "segmentation-45\n",
      "segmentation-46\n",
      "segmentation-47\n",
      "segmentation-48\n",
      "segmentation-49\n",
      "segmentation-5\n",
      "segmentation-50\n",
      "segmentation-51\n",
      "segmentation-52\n",
      "segmentation-53\n",
      "segmentation-54\n",
      "segmentation-55\n",
      "segmentation-56\n",
      "segmentation-57\n",
      "segmentation-58\n",
      "segmentation-59\n",
      "segmentation-6\n",
      "segmentation-60\n",
      "segmentation-61\n",
      "segmentation-62\n",
      "segmentation-63\n",
      "segmentation-64\n",
      "segmentation-65\n",
      "segmentation-66\n",
      "segmentation-67\n",
      "segmentation-68\n",
      "segmentation-69\n",
      "segmentation-7\n",
      "segmentation-70\n",
      "segmentation-71\n",
      "segmentation-72\n",
      "segmentation-73\n",
      "segmentation-74\n",
      "segmentation-75\n",
      "segmentation-76\n",
      "segmentation-77\n",
      "segmentation-78\n",
      "segmentation-79\n",
      "segmentation-8\n",
      "segmentation-80\n",
      "segmentation-81\n",
      "segmentation-82\n",
      "segmentation-83\n",
      "segmentation-84\n",
      "segmentation-85\n",
      "segmentation-86\n",
      "segmentation-87\n",
      "segmentation-88\n",
      "segmentation-89\n",
      "segmentation-9\n",
      "segmentation-90\n",
      "segmentation-91\n",
      "segmentation-92\n",
      "segmentation-93\n",
      "segmentation-94\n",
      "segmentation-95\n",
      "segmentation-96\n",
      "segmentation-97\n",
      "segmentation-98\n",
      "segmentation-99\n",
      "segmentation-125\n",
      "133\n",
      "segmentation-127\n",
      "270\n",
      "segmentation-129\n",
      "325\n",
      "segmentation-14\n",
      "164\n",
      "segmentation-16\n",
      "222\n",
      "segmentation-18\n",
      "224\n",
      "segmentation-2\n",
      "164\n",
      "segmentation-21\n",
      "191\n",
      "segmentation-23\n",
      "137\n",
      "segmentation-25\n",
      "277\n",
      "segmentation-27\n",
      "272\n",
      "segmentation-29\n",
      "135\n",
      "segmentation-30\n",
      "146\n",
      "segmentation-32\n",
      "128\n",
      "segmentation-34\n",
      "109\n",
      "volume-0\n",
      "volume-1\n",
      "volume-10\n",
      "volume-100\n",
      "volume-101\n",
      "volume-102\n",
      "volume-103\n",
      "volume-104\n",
      "volume-105\n",
      "volume-106\n",
      "volume-107\n",
      "volume-108\n",
      "volume-109\n",
      "volume-11\n",
      "volume-110\n",
      "volume-111\n",
      "volume-112\n",
      "volume-113\n",
      "volume-114\n",
      "volume-115\n",
      "volume-116\n",
      "volume-117\n",
      "volume-118\n",
      "volume-119\n",
      "volume-12\n",
      "volume-120\n",
      "volume-121\n",
      "volume-122\n",
      "volume-123\n",
      "volume-124\n",
      "volume-126\n",
      "volume-128\n",
      "volume-13\n",
      "volume-15\n",
      "volume-17\n",
      "volume-19\n",
      "volume-20\n",
      "volume-22\n",
      "volume-24\n",
      "volume-26\n",
      "volume-28\n",
      "volume-3\n",
      "volume-31\n",
      "volume-33\n",
      "volume-35\n",
      "volume-36\n",
      "volume-37\n",
      "volume-38\n",
      "volume-39\n",
      "volume-4\n",
      "volume-40\n",
      "volume-41\n",
      "volume-42\n",
      "volume-43\n",
      "volume-44\n",
      "volume-45\n",
      "volume-46\n",
      "volume-47\n",
      "volume-48\n",
      "volume-49\n",
      "volume-5\n",
      "volume-50\n",
      "volume-51\n",
      "volume-52\n",
      "volume-53\n",
      "volume-54\n",
      "volume-55\n",
      "volume-56\n",
      "volume-57\n",
      "volume-58\n",
      "volume-59\n",
      "volume-6\n",
      "volume-60\n",
      "volume-61\n",
      "volume-62\n",
      "volume-63\n",
      "volume-64\n",
      "volume-65\n",
      "volume-66\n",
      "volume-67\n",
      "volume-68\n",
      "volume-69\n",
      "volume-7\n",
      "volume-70\n",
      "volume-71\n",
      "volume-72\n",
      "volume-73\n",
      "volume-74\n",
      "volume-75\n",
      "volume-76\n",
      "volume-77\n",
      "volume-78\n",
      "volume-79\n",
      "volume-8\n",
      "volume-80\n",
      "volume-81\n",
      "volume-82\n",
      "volume-83\n",
      "volume-84\n",
      "volume-85\n",
      "volume-86\n",
      "volume-87\n",
      "volume-88\n",
      "volume-89\n",
      "volume-9\n",
      "volume-90\n",
      "volume-91\n",
      "volume-92\n",
      "volume-93\n",
      "volume-94\n",
      "volume-95\n",
      "volume-96\n",
      "volume-97\n",
      "volume-98\n",
      "volume-99\n",
      "volume-125\n",
      "volume-127\n",
      "volume-129\n",
      "volume-14\n",
      "volume-16\n",
      "volume-18\n",
      "volume-2\n",
      "volume-21\n",
      "volume-23\n",
      "volume-25\n",
      "volume-27\n",
      "volume-29\n",
      "volume-30\n",
      "volume-32\n",
      "volume-34\n"
     ]
    }
   ],
   "source": [
    "#npy를 slice별로 나누어 하나의 list저장\n",
    "seg_list_train=[]\n",
    "seg_list_test=[]\n",
    "for file in segmentation_data:\n",
    "    fname=os.path.basename(file)\n",
    "    print(fname)\n",
    "    img_array=np.load(data_path+fname+'.npy')\n",
    "    \n",
    "    #print(f'img_num: {img_array.shape}')\n",
    "    \n",
    "    if len(img_array.shape) == 3:\n",
    "        nx, ny, nz = img_array.shape\n",
    "        total_slices = img_array.shape[2]\n",
    "        #print(total_slices)\n",
    "        # iterate through slices\n",
    "        for current_slice in range(0, total_slices):\n",
    "            seg_list_train.append(img_array[:,:,current_slice]) \n",
    "\n",
    "for file in seg_data_test:\n",
    "    fname=os.path.basename(file)\n",
    "    print(fname)\n",
    "    img_array=np.load(data_path+fname+'.npy')\n",
    "    \n",
    "    #print(f'img_num: {img_array.shape}')\n",
    "    \n",
    "    if len(img_array.shape) == 3:\n",
    "        nx, ny, nz = img_array.shape\n",
    "        total_slices = img_array.shape[2]\n",
    "        print(total_slices)\n",
    "        # iterate through slices\n",
    "        for current_slice in range(0, total_slices):\n",
    "            seg_list_test.append(img_array[:,:,current_slice]) \n",
    "#간 1, 병변 2, 나머지 0\n",
    "\n",
    "\n",
    "vol_list_train=[]\n",
    "vol_list_test=[]\n",
    "for file in volume_data:\n",
    "    fname=os.path.basename(file)\n",
    "    print(fname)\n",
    "    img_array=np.load(data_path+fname+'.npy')\n",
    "    \n",
    "    #print(f'img_num: {img_array.shape}')\n",
    "    \n",
    "    if len(img_array.shape) == 3:\n",
    "        nx, ny, nz = img_array.shape\n",
    "        total_slices = img_array.shape[2]\n",
    "        # iterate through slices\n",
    "        for current_slice in range(0, total_slices):\n",
    "            vol_list_train.append(img_array[:,:,current_slice]) \n",
    "            \n",
    "for file in vol_data_test:\n",
    "    fname=os.path.basename(file)\n",
    "    print(fname)\n",
    "    img_array=np.load(data_path+fname+'.npy')\n",
    "    \n",
    "    #print(f'img_num: {img_array.shape}')\n",
    "    \n",
    "    if len(img_array.shape) == 3:\n",
    "        nx, ny, nz = img_array.shape\n",
    "        total_slices = img_array.shape[2]\n",
    "        # iterate through slices\n",
    "        for current_slice in range(0, total_slices):\n",
    "            vol_list_test.append(img_array[:,:,current_slice]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label을 만들어 list에 저장\n",
    "labels_train = []\n",
    "labels_test=[]\n",
    "for i in seg_list_test:\n",
    "    if 2 in i:\n",
    "        labels_test.append(1)\n",
    "    else:\n",
    "        labels_test.append(0)\n",
    "        \n",
    "for i in seg_list_train:\n",
    "    if 2 in i:\n",
    "        labels_train.append(1)\n",
    "    else:\n",
    "        labels_train.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(nparray):\n",
    "    # normalize scans to [0,1]\n",
    "    _min = nparray.min()\n",
    "    _max = nparray.max()\n",
    "    nparray = nparray - _min\n",
    "    nparray = nparray / (_max - _min)\n",
    "    return nparray\n",
    "\n",
    "def norm_zscore(nparray):\n",
    "    # normalize 2d scands by mean and standard deviation\n",
    "    mean = nparray.mean()\n",
    "    std = nparray.std()    \n",
    "    nparray = nparray - mean\n",
    "    nparray /= std\n",
    "    return nparray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_MAX = 200\n",
    "WINDOW_MIN = 0\n",
    "GLOBAL_PIXEL_MEAN = 0.1\n",
    "\n",
    "class CustomDataset(Dataset): \n",
    "  def __init__(self,volume_list,all_labels,transforms=None):\n",
    "    self.volume_list=volume_list\n",
    "    self.all_labels=all_labels\n",
    "    self.length=len(all_labels)\n",
    "    self.transforms=transforms\n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    npy=self.volume_list[idx]\n",
    "\n",
    "    npy[npy > WINDOW_MAX] = WINDOW_MAX\n",
    "    npy[npy < WINDOW_MIN] = WINDOW_MIN\n",
    "    \n",
    "    npy = (npy - WINDOW_MIN) / (WINDOW_MAX - WINDOW_MIN)\n",
    "    npy -= GLOBAL_PIXEL_MEAN\n",
    "    \n",
    "    if len(npy.shape)==2:\n",
    "      npy=npy[:,:,np.newaxis].astype(dtype='float32')\n",
    "    \n",
    "    if self.transforms is not None:\n",
    "      npy=self.transforms(npy)\n",
    "    \n",
    "    return{'npy':npy,'label':self.all_labels[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "resnet18_pretrained=models.resnet18(pretrained=True)\n",
    "print(resnet18_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiverResnet(nn.Module):\n",
    "    def __init__(self,in_channels=1):\n",
    "        super(LiverResnet,self).__init__()\n",
    "        \n",
    "        #torchvision.models에서 사전훈련된 resnet모델 가져오기\n",
    "        self.model=models.resnet18(pretrained=True)\n",
    "        \n",
    "        #기본채널이 3이기 때문에 liver data set에 맞게 1로 바꿔줌\n",
    "        #원래 resnet의 첫번째 layer\n",
    "        # self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.model.conv1=nn.Conv2d(in_channels,64,kernel_size=7,stride=2,padding=3,bias=False)\n",
    "        \n",
    "        #class수 변경\n",
    "        num_ftrs=self.model.fc.in_features\n",
    "        self.model.fc=nn.Linear(num_ftrs,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "            return self.model(x)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LiverResnet(\n",
      "  (model): ResNet(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=LiverResnet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([transforms.ToTensor()\n",
    "                                       ])\n",
    "transforms_test = transforms.Compose([transforms.ToTensor()\n",
    "                                       ])\n",
    "\n",
    "hyper_param_epoch=10\n",
    "hyper_param_batch=8\n",
    "hyper_param_learning_rate=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vol_train, vol_valid, lab_train, lab_valid = train_test_split(volume_list, all_labels, test_size=0.3, shuffle=True, stratify=all_labels, random_state=34)\n",
    "train_dataset=CustomDataset(volume_list=vol_list_train, all_labels=labels_train,transforms=transforms_train)\n",
    "test_dataset=CustomDataset(volume_list=vol_list_test,all_labels=labels_test,transforms=transforms_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=hyper_param_batch, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=hyper_param_batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 / 1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device,\"/\" ,torch.cuda.device_count())\n",
    "\n",
    "custom_model=LiverResnet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(custom_model.parameters(), lr=hyper_param_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loss(model):\n",
    "    total_loss=0\n",
    "    for i_batch, item in enumerate(test_loader):\n",
    "        npys = item['npy'].to(device)\n",
    "        labels = item['label'].to(device)\n",
    "        if(len(labels)!=hyper_param_batch):\n",
    "            break\n",
    "        outputs =model(npys)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_loss+=loss.item()\n",
    "    return total_loss/(i_batch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10],i_batch=2414 ,Train_Loss: 0.2444,Valid_loss: 0.5907\n",
      "Time: 1574.8104836940765sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d2f02076a807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mval_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mtrain_loss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mvalid_loss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-c656327cec56>\u001b[0m in \u001b[0;36mvalidation_loss\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtotal_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mnpys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'npy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-13d717f8bcb3>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0mnpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'npy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnpy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mpic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;31m# backward compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_value=1\n",
    "start=time.time()\n",
    "custom_model.train()\n",
    "train_loss_history=[]\n",
    "valid_loss_history=[]\n",
    "for e in range(hyper_param_epoch):\n",
    "        for i_batch, item in enumerate(train_loader):\n",
    "                npys = item['npy'].to(device)\n",
    "                labels = item['label'].to(device)\n",
    "                if(len(labels)!=hyper_param_batch):\n",
    "                        break\n",
    "                #print(npys)\n",
    "                # Forward pass\n",
    "                outputs =custom_model(npys)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "        val_loss=validation_loss(custom_model)\n",
    "        train_loss_history.append(loss.item())\n",
    "        valid_loss_history.append(val_loss)\n",
    "        print('Epoch [{}/{}],i_batch={} ,Train_Loss: {:.4f},Valid_loss: {:.4f}'\n",
    "                                        .format(e + 1, hyper_param_epoch, i_batch+1, loss.item(),val_loss))\n",
    "        print(\"Time: {}sec\".format(time.time()-start))\n",
    "        start=time.time()\n",
    "        if loss_value>val_loss:\n",
    "                loss_value=val_loss\n",
    "                torch.save({\n",
    "                'epoch': e,\n",
    "                'model_state_dict': custom_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                }, '/home/sumins/workspace/model_check/resnet18.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_history)\n",
    "plt.plot(valid_loss_history)\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "with open(\"valid_loss_history_resnet18.csv\", 'w') as file:\n",
    "  writer = csv.writer(file)\n",
    "  writer.writerow(valid_loss_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "with open(\"train_loss_history_resnet18.csv\", 'w') as file:\n",
    "  writer = csv.writer(file)\n",
    "  writer.writerow(train_loss_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7323, device='cuda:0', requires_grad=True)\n",
      "Test Accuracy of the model on the 2897 test images: 84.91542975491888 %\n"
     ]
    }
   ],
   "source": [
    "true_label=[]\n",
    "pred_label=[]\n",
    "\n",
    "model=LiverResnet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyper_param_learning_rate)\n",
    "\n",
    "checkpoint = torch.load('/home/sumins/workspace/model_check/model_alexnet.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "print(loss)\n",
    "custom_model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for item in test_loader:\n",
    "        npys = item['npy'].to(device)\n",
    "        labels = item['label'].to(device)\n",
    "        \n",
    "        outputs =model(npys)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        true_label.extend(labels)\n",
    "        pred_label.extend(predicted)\n",
    "        total += len(labels)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('Test Accuracy of the model on the {} test images: {} %'.format(total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90      2155\n",
      "           1       0.71      0.69      0.70       742\n",
      "\n",
      "    accuracy                           0.85      2897\n",
      "   macro avg       0.80      0.80      0.80      2897\n",
      "weighted avg       0.85      0.85      0.85      2897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true_labels=torch.tensor(true_label)\n",
    "true_labels=true_labels.tolist()\n",
    "pred_labels=torch.tensor(pred_label)\n",
    "pred_labels=pred_labels.tolist()\n",
    "print(classification_report(true_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7323, device='cuda:0', requires_grad=True)\n",
      "Test Accuracy of the model on the 19310 train images: 97.1620921802175 %\n"
     ]
    }
   ],
   "source": [
    "true_label1=[]\n",
    "pred_label1=[]\n",
    "\n",
    "model=LiverResnet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyper_param_learning_rate)\n",
    "\n",
    "checkpoint = torch.load('/home/sumins/workspace/model_check/model_alexnet.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "print(loss)\n",
    "custom_model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for item in train_loader:\n",
    "        npys = item['npy'].to(device)\n",
    "        labels = item['label'].to(device)\n",
    "        \n",
    "        outputs =model(npys)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        true_label1.extend(labels)\n",
    "        pred_label1.extend(predicted)\n",
    "        total += len(labels)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('Test Accuracy of the model on the {} train images: {} %'.format(total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     13062\n",
      "           1       1.00      1.00      1.00      6248\n",
      "\n",
      "    accuracy                           1.00     19310\n",
      "   macro avg       1.00      1.00      1.00     19310\n",
      "weighted avg       1.00      1.00      1.00     19310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true_labels1=torch.tensor(true_label1)\n",
    "true_labels1=true_labels1.tolist()\n",
    "pred_labels1=torch.tensor(pred_label1)\n",
    "pred_labels1=pred_labels1.tolist()\n",
    "print(classification_report(true_labels1,pred_labels1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
