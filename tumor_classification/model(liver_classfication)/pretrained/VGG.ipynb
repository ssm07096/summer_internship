{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import nibabel as nib\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchsummary\n",
    "from torchvision import transforms, models\n",
    "import time\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일이름 sort해서 list저장\n",
    "data_path='/disk1/data_liverbound_noclip/'\n",
    "name_list=os.listdir(data_path)\n",
    "\n",
    "segmentation_data = [files[:-4] for files in name_list if files.startswith('segmentation')]\n",
    "segmentation_data=list(set(segmentation_data))\n",
    "segmentation_data.sort()\n",
    "seg_data_test=[]\n",
    "for i in range(30,45):\n",
    "    seg_data_test.append(segmentation_data.pop(i))\n",
    "\n",
    "volume_data=[files[:-4] for files in name_list if files.startswith('volume')]\n",
    "volume_data=list(set(volume_data))\n",
    "volume_data.sort()\n",
    "vol_data_test=[]\n",
    "for i in range(30,45):\n",
    "    vol_data_test.append(volume_data.pop(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_labels=np.loadtxt('/home/sumins/workspace/liver_classification/all_labels.txt',dtype=int)\n",
    "# all_labels=all_labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmentation-0\n",
      "segmentation-1\n",
      "segmentation-10\n",
      "segmentation-100\n",
      "segmentation-101\n",
      "segmentation-102\n",
      "segmentation-103\n",
      "segmentation-104\n",
      "segmentation-105\n",
      "segmentation-106\n",
      "segmentation-107\n",
      "segmentation-108\n",
      "segmentation-109\n",
      "segmentation-11\n",
      "segmentation-110\n",
      "segmentation-111\n",
      "segmentation-112\n",
      "segmentation-113\n",
      "segmentation-114\n",
      "segmentation-115\n",
      "segmentation-116\n",
      "segmentation-117\n",
      "segmentation-118\n",
      "segmentation-119\n",
      "segmentation-12\n",
      "segmentation-120\n",
      "segmentation-121\n",
      "segmentation-122\n",
      "segmentation-123\n",
      "segmentation-124\n",
      "segmentation-126\n",
      "segmentation-128\n",
      "segmentation-13\n",
      "segmentation-15\n",
      "segmentation-17\n",
      "segmentation-19\n",
      "segmentation-20\n",
      "segmentation-22\n",
      "segmentation-24\n",
      "segmentation-26\n",
      "segmentation-28\n",
      "segmentation-3\n",
      "segmentation-31\n",
      "segmentation-33\n",
      "segmentation-35\n",
      "segmentation-36\n",
      "segmentation-37\n",
      "segmentation-38\n",
      "segmentation-39\n",
      "segmentation-4\n",
      "segmentation-40\n",
      "segmentation-41\n",
      "segmentation-42\n",
      "segmentation-43\n",
      "segmentation-44\n",
      "segmentation-45\n",
      "segmentation-46\n",
      "segmentation-47\n",
      "segmentation-48\n",
      "segmentation-49\n",
      "segmentation-5\n",
      "segmentation-50\n",
      "segmentation-51\n",
      "segmentation-52\n",
      "segmentation-53\n",
      "segmentation-54\n",
      "segmentation-55\n",
      "segmentation-56\n",
      "segmentation-57\n",
      "segmentation-58\n",
      "segmentation-59\n",
      "segmentation-6\n",
      "segmentation-60\n",
      "segmentation-61\n",
      "segmentation-62\n",
      "segmentation-63\n",
      "segmentation-64\n",
      "segmentation-65\n",
      "segmentation-66\n",
      "segmentation-67\n",
      "segmentation-68\n",
      "segmentation-69\n",
      "segmentation-7\n",
      "segmentation-70\n",
      "segmentation-71\n",
      "segmentation-72\n",
      "segmentation-73\n",
      "segmentation-74\n",
      "segmentation-75\n",
      "segmentation-76\n",
      "segmentation-77\n",
      "segmentation-78\n",
      "segmentation-79\n",
      "segmentation-8\n",
      "segmentation-80\n",
      "segmentation-81\n",
      "segmentation-82\n",
      "segmentation-83\n",
      "segmentation-84\n",
      "segmentation-85\n",
      "segmentation-86\n",
      "segmentation-87\n",
      "segmentation-88\n",
      "segmentation-89\n",
      "segmentation-9\n",
      "segmentation-90\n",
      "segmentation-91\n",
      "segmentation-92\n",
      "segmentation-93\n",
      "segmentation-94\n",
      "segmentation-95\n",
      "segmentation-96\n",
      "segmentation-97\n",
      "segmentation-98\n",
      "segmentation-99\n",
      "segmentation-125\n",
      "133\n",
      "segmentation-127\n",
      "270\n",
      "segmentation-129\n",
      "325\n",
      "segmentation-14\n",
      "164\n",
      "segmentation-16\n",
      "222\n",
      "segmentation-18\n",
      "224\n",
      "segmentation-2\n",
      "164\n",
      "segmentation-21\n",
      "191\n",
      "segmentation-23\n",
      "137\n",
      "segmentation-25\n",
      "277\n",
      "segmentation-27\n",
      "272\n",
      "segmentation-29\n",
      "135\n",
      "segmentation-30\n",
      "146\n",
      "segmentation-32\n",
      "128\n",
      "segmentation-34\n",
      "109\n",
      "volume-0\n",
      "volume-1\n",
      "volume-10\n",
      "volume-100\n",
      "volume-101\n",
      "volume-102\n",
      "volume-103\n",
      "volume-104\n",
      "volume-105\n",
      "volume-106\n",
      "volume-107\n",
      "volume-108\n",
      "volume-109\n",
      "volume-11\n",
      "volume-110\n",
      "volume-111\n",
      "volume-112\n",
      "volume-113\n",
      "volume-114\n",
      "volume-115\n",
      "volume-116\n",
      "volume-117\n",
      "volume-118\n",
      "volume-119\n",
      "volume-12\n",
      "volume-120\n",
      "volume-121\n",
      "volume-122\n",
      "volume-123\n",
      "volume-124\n",
      "volume-126\n",
      "volume-128\n",
      "volume-13\n",
      "volume-15\n",
      "volume-17\n",
      "volume-19\n",
      "volume-20\n",
      "volume-22\n",
      "volume-24\n",
      "volume-26\n",
      "volume-28\n",
      "volume-3\n",
      "volume-31\n",
      "volume-33\n",
      "volume-35\n",
      "volume-36\n",
      "volume-37\n",
      "volume-38\n",
      "volume-39\n",
      "volume-4\n",
      "volume-40\n",
      "volume-41\n",
      "volume-42\n",
      "volume-43\n",
      "volume-44\n",
      "volume-45\n",
      "volume-46\n",
      "volume-47\n",
      "volume-48\n",
      "volume-49\n",
      "volume-5\n",
      "volume-50\n",
      "volume-51\n",
      "volume-52\n",
      "volume-53\n",
      "volume-54\n",
      "volume-55\n",
      "volume-56\n",
      "volume-57\n",
      "volume-58\n",
      "volume-59\n",
      "volume-6\n",
      "volume-60\n",
      "volume-61\n",
      "volume-62\n",
      "volume-63\n",
      "volume-64\n",
      "volume-65\n",
      "volume-66\n",
      "volume-67\n",
      "volume-68\n",
      "volume-69\n",
      "volume-7\n",
      "volume-70\n",
      "volume-71\n",
      "volume-72\n",
      "volume-73\n",
      "volume-74\n",
      "volume-75\n",
      "volume-76\n",
      "volume-77\n",
      "volume-78\n",
      "volume-79\n",
      "volume-8\n",
      "volume-80\n",
      "volume-81\n",
      "volume-82\n",
      "volume-83\n",
      "volume-84\n",
      "volume-85\n",
      "volume-86\n",
      "volume-87\n",
      "volume-88\n",
      "volume-89\n",
      "volume-9\n",
      "volume-90\n",
      "volume-91\n",
      "volume-92\n",
      "volume-93\n",
      "volume-94\n",
      "volume-95\n",
      "volume-96\n",
      "volume-97\n",
      "volume-98\n",
      "volume-99\n",
      "volume-125\n",
      "volume-127\n",
      "volume-129\n",
      "volume-14\n",
      "volume-16\n",
      "volume-18\n",
      "volume-2\n",
      "volume-21\n",
      "volume-23\n",
      "volume-25\n",
      "volume-27\n",
      "volume-29\n",
      "volume-30\n",
      "volume-32\n",
      "volume-34\n"
     ]
    }
   ],
   "source": [
    "#npy를 slice별로 나누어 하나의 list저장\n",
    "seg_list_train=[]\n",
    "seg_list_test=[]\n",
    "for file in segmentation_data:\n",
    "    fname=os.path.basename(file)\n",
    "    print(fname)\n",
    "    img_array=np.load(data_path+fname+'.npy')\n",
    "    \n",
    "    #print(f'img_num: {img_array.shape}')\n",
    "    \n",
    "    if len(img_array.shape) == 3:\n",
    "        nx, ny, nz = img_array.shape\n",
    "        total_slices = img_array.shape[2]\n",
    "        #print(total_slices)\n",
    "        # iterate through slices\n",
    "        for current_slice in range(0, total_slices):\n",
    "            seg_list_train.append(img_array[:,:,current_slice]) \n",
    "\n",
    "for file in seg_data_test:\n",
    "    fname=os.path.basename(file)\n",
    "    print(fname)\n",
    "    img_array=np.load(data_path+fname+'.npy')\n",
    "    \n",
    "    #print(f'img_num: {img_array.shape}')\n",
    "    \n",
    "    if len(img_array.shape) == 3:\n",
    "        nx, ny, nz = img_array.shape\n",
    "        total_slices = img_array.shape[2]\n",
    "        print(total_slices)\n",
    "        # iterate through slices\n",
    "        for current_slice in range(0, total_slices):\n",
    "            seg_list_test.append(img_array[:,:,current_slice]) \n",
    "#간 1, 병변 2, 나머지 0\n",
    "\n",
    "\n",
    "vol_list_train=[]\n",
    "vol_list_test=[]\n",
    "for file in volume_data:\n",
    "    fname=os.path.basename(file)\n",
    "    print(fname)\n",
    "    img_array=np.load(data_path+fname+'.npy')\n",
    "    \n",
    "    #print(f'img_num: {img_array.shape}')\n",
    "    \n",
    "    if len(img_array.shape) == 3:\n",
    "        nx, ny, nz = img_array.shape\n",
    "        total_slices = img_array.shape[2]\n",
    "        # iterate through slices\n",
    "        for current_slice in range(0, total_slices):\n",
    "            vol_list_train.append(img_array[:,:,current_slice]) \n",
    "            \n",
    "for file in vol_data_test:\n",
    "    fname=os.path.basename(file)\n",
    "    print(fname)\n",
    "    img_array=np.load(data_path+fname+'.npy')\n",
    "    \n",
    "    #print(f'img_num: {img_array.shape}')\n",
    "    \n",
    "    if len(img_array.shape) == 3:\n",
    "        nx, ny, nz = img_array.shape\n",
    "        total_slices = img_array.shape[2]\n",
    "        # iterate through slices\n",
    "        for current_slice in range(0, total_slices):\n",
    "            vol_list_test.append(img_array[:,:,current_slice]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label을 만들어 list에 저장\n",
    "labels_train = []\n",
    "labels_test=[]\n",
    "for i in seg_list_test:\n",
    "    if 2 in i:\n",
    "        labels_test.append(1)\n",
    "    else:\n",
    "        labels_test.append(0)\n",
    "        \n",
    "for i in seg_list_train:\n",
    "    if 2 in i:\n",
    "        labels_train.append(1)\n",
    "    else:\n",
    "        labels_train.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(nparray):\n",
    "    # normalize scans to [0,1]\n",
    "    _min = nparray.min()\n",
    "    _max = nparray.max()\n",
    "    nparray = nparray - _min\n",
    "    nparray = nparray / (_max - _min)\n",
    "    return nparray\n",
    "\n",
    "def norm_zscore(nparray):\n",
    "    # normalize 2d scands by mean and standard deviation\n",
    "    mean = nparray.mean()\n",
    "    std = nparray.std()    \n",
    "    nparray = nparray - mean\n",
    "    nparray /= std\n",
    "    return nparray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_MAX = 130\n",
    "WINDOW_MIN = -30\n",
    "GLOBAL_PIXEL_MEAN = 0.1\n",
    "\n",
    "class CustomDataset(Dataset): \n",
    "  def __init__(self,volume_list,all_labels,transforms=None):\n",
    "    self.volume_list=volume_list\n",
    "    self.all_labels=all_labels\n",
    "    self.length=len(all_labels)\n",
    "    self.transforms=transforms\n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    npy=self.volume_list[idx]\n",
    "\n",
    "    npy[npy > WINDOW_MAX] = WINDOW_MAX\n",
    "    npy[npy < WINDOW_MIN] = WINDOW_MIN\n",
    "    \n",
    "    npy = (npy - WINDOW_MIN) / (WINDOW_MAX - WINDOW_MIN)\n",
    "    npy -= GLOBAL_PIXEL_MEAN\n",
    "    \n",
    "    if len(npy.shape)==2:\n",
    "      npy=npy[:,:,np.newaxis].astype(dtype='float32')\n",
    "    \n",
    "    if self.transforms is not None:\n",
    "      npy=self.transforms(npy)\n",
    "    \n",
    "    return{'npy':npy,'label':self.all_labels[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "VGG16_pretrained=models.vgg16(pretrained=True)\n",
    "print(VGG16_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customVGG16(nn.Module):\n",
    "    def __init__(self,in_channels=1):\n",
    "        super(customVGG16,self).__init__()\n",
    "        \n",
    "        #torchvision.models에서 사전훈련된 resnet모델 가져오기\n",
    "        self.model=models.vgg16(pretrained=True)\n",
    "        \n",
    "        #기본채널이 3이기 때문에 liver data set에 맞게 1로 바꿔줌\n",
    "        #원래 resnet의 첫번째 layer\n",
    "        #Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.model.features[0]=nn.Conv2d(in_channels,64,kernel_size=3,stride=1,padding=1)\n",
    "        \n",
    "        # class수 변경\n",
    "        num_ftrs=self.model.classifier[6].in_features\n",
    "        self.model.classifier[6]=nn.Linear(num_ftrs,2)\n",
    "        \n",
    "        for params in model.parameters():\n",
    "            params.requires_grad=False\n",
    "        for name, params in model.named_parameters():\n",
    "            if name in ['features.0.weight','classifier.0.weight','classifier.3.weight','classifier.6.weight']:\n",
    "                params.requires_grad = True\n",
    "        \n",
    "    def forward(self,x):\n",
    "            return self.model(x)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customVGG16(\n",
      "  (model): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): ReLU(inplace=True)\n",
      "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): ReLU(inplace=True)\n",
      "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): ReLU(inplace=True)\n",
      "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (22): ReLU(inplace=True)\n",
      "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (25): ReLU(inplace=True)\n",
      "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (27): ReLU(inplace=True)\n",
      "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (29): ReLU(inplace=True)\n",
      "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "odict_keys(['model.features.0.weight', 'model.features.0.bias', 'model.features.2.weight', 'model.features.2.bias', 'model.features.5.weight', 'model.features.5.bias', 'model.features.7.weight', 'model.features.7.bias', 'model.features.10.weight', 'model.features.10.bias', 'model.features.12.weight', 'model.features.12.bias', 'model.features.14.weight', 'model.features.14.bias', 'model.features.17.weight', 'model.features.17.bias', 'model.features.19.weight', 'model.features.19.bias', 'model.features.21.weight', 'model.features.21.bias', 'model.features.24.weight', 'model.features.24.bias', 'model.features.26.weight', 'model.features.26.bias', 'model.features.28.weight', 'model.features.28.bias', 'model.classifier.0.weight', 'model.classifier.0.bias', 'model.classifier.3.weight', 'model.classifier.3.bias', 'model.classifier.6.weight', 'model.classifier.6.bias'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=customVGG16()\n",
    "print(model)\n",
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([transforms.ToTensor()\n",
    "                                       ])\n",
    "transforms_test = transforms.Compose([transforms.ToTensor()\n",
    "                                       ])\n",
    "\n",
    "hyper_param_epoch=10\n",
    "hyper_param_batch=8\n",
    "hyper_param_learning_rate=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vol_train, vol_valid, lab_train, lab_valid = train_test_split(volume_list, all_labels, test_size=0.3, shuffle=True, stratify=all_labels, random_state=34)\n",
    "train_dataset=CustomDataset(volume_list=vol_list_train, all_labels=labels_train,transforms=transforms_train)\n",
    "test_dataset=CustomDataset(volume_list=vol_list_test,all_labels=labels_test,transforms=transforms_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=hyper_param_batch, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=hyper_param_batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 / 1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device,\"/\" ,torch.cuda.device_count())\n",
    "\n",
    "custom_model=customVGG16().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(custom_model.parameters(), lr=hyper_param_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loss(model):\n",
    "    total_loss=0\n",
    "    for i_batch, item in enumerate(test_loader):\n",
    "        npys = item['npy'].to(device)\n",
    "        labels = item['label'].to(device)\n",
    "        if(len(labels)!=hyper_param_batch):\n",
    "            break\n",
    "        outputs =model(npys)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_loss+=loss.item()\n",
    "    return total_loss/(i_batch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "loss_value=1\n",
    "start=time.time()\n",
    "custom_model.train()\n",
    "train_loss_history=[]\n",
    "valid_loss_history=[]\n",
    "for e in range(hyper_param_epoch):\n",
    "        for i_batch, item in enumerate(train_loader):\n",
    "                npys = item['npy'].to(device)\n",
    "                labels = item['label'].to(device)\n",
    "                if(len(labels)!=hyper_param_batch):\n",
    "                        break\n",
    "                #print(npys)\n",
    "                # Forward pass\n",
    "                outputs =custom_model(npys)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "        val_loss=validation_loss(custom_model)\n",
    "        train_loss_history.append(loss.item())\n",
    "        valid_loss_history.append(val_loss)\n",
    "        print('Epoch [{}/{}],i_batch={} ,Train_Loss: {:.4f},Valid_loss: {:.4f}'\n",
    "                                        .format(e + 1, hyper_param_epoch, i_batch+1, loss.item(),val_loss))\n",
    "        print(\"Time: {}sec\".format(time.time()-start))\n",
    "        start=time.time()\n",
    "        if loss_value>val_loss:\n",
    "                loss_value=val_loss\n",
    "                torch.save({\n",
    "                'epoch': e,\n",
    "                'model_state_dict': custom_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                }, '/home/sumins/workspace/model_check/vgg16.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_history)\n",
    "plt.plot(valid_loss_history)\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "with open(\"valid_vgg.csv\", 'w') as file:\n",
    "  writer = csv.writer(file)\n",
    "  writer.writerow(valid_loss_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "with open(\"train_vgg.csv\", 'w') as file:\n",
    "  writer = csv.writer(file)\n",
    "  writer.writerow(train_loss_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4710, device='cuda:0', requires_grad=True)\n",
      "Test Accuracy of the model on the 2897 test images: 70.45219192267864 %\n"
     ]
    }
   ],
   "source": [
    "true_label=[]\n",
    "pred_label=[]\n",
    "\n",
    "model=customVGG16().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyper_param_learning_rate)\n",
    "\n",
    "checkpoint = torch.load('/home/sumins/workspace/model_check/model_vgg16.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "print(loss)\n",
    "custom_model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for item in test_loader:\n",
    "        npys = item['npy'].to(device)\n",
    "        labels = item['label'].to(device)\n",
    "        \n",
    "        outputs =model(npys)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        true_label.extend(labels)\n",
    "        pred_label.extend(predicted)\n",
    "        total += len(labels)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('Test Accuracy of the model on the {} test images: {} %'.format(total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      2155\n",
      "           1       0.42      0.40      0.41       742\n",
      "\n",
      "    accuracy                           0.70      2897\n",
      "   macro avg       0.61      0.61      0.61      2897\n",
      "weighted avg       0.70      0.70      0.70      2897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true_labels=torch.tensor(true_label)\n",
    "true_labels=true_labels.tolist()\n",
    "pred_labels=torch.tensor(pred_label)\n",
    "pred_labels=pred_labels.tolist()\n",
    "print(classification_report(true_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4710, device='cuda:0', requires_grad=True)\n",
      "Test Accuracy of the model on the 19310 train images: 81.70895908855515 %\n"
     ]
    }
   ],
   "source": [
    "true_label1=[]\n",
    "pred_label1=[]\n",
    "\n",
    "model=customVGG16().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyper_param_learning_rate)\n",
    "\n",
    "checkpoint = torch.load('/home/sumins/workspace/model_check/model_vgg16.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "print(loss)\n",
    "custom_model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for item in train_loader:\n",
    "        npys = item['npy'].to(device)\n",
    "        labels = item['label'].to(device)\n",
    "        \n",
    "        outputs =model(npys)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        true_label1.extend(labels)\n",
    "        pred_label1.extend(predicted)\n",
    "        total += len(labels)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('Test Accuracy of the model on the {} train images: {} %'.format(total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87     13062\n",
      "           1       0.76      0.64      0.69      6248\n",
      "\n",
      "    accuracy                           0.82     19310\n",
      "   macro avg       0.80      0.77      0.78     19310\n",
      "weighted avg       0.81      0.82      0.81     19310\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "true_labels1=torch.tensor(true_label1)\n",
    "true_labels1=true_labels1.tolist()\n",
    "pred_labels1=torch.tensor(pred_label1)\n",
    "pred_labels1=pred_labels1.tolist()\n",
    "print(classification_report(true_labels1,pred_labels1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
