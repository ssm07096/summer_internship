{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import nibabel as nib\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchsummary\n",
    "from torchvision import transforms\n",
    "import time\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일이름 sort해서 list저장\n",
    "data_path='/disk1/data_liverbound_noclip/'\n",
    "name_list=os.listdir(data_path)\n",
    "\n",
    "segmentation_data = [files[:-4] for files in name_list if files.startswith('segmentation')]\n",
    "segmentation_data=list(set(segmentation_data))\n",
    "segmentation_data.sort()\n",
    "\n",
    "volume_data=[files[:-4] for files in name_list if files.startswith('volume')]\n",
    "volume_data=list(set(volume_data))\n",
    "volume_data.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels=np.loadtxt('/home/sumins/workspace/liver_classification/all_labels.txt',dtype=int)\n",
    "all_labels=all_labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume-0\n",
      "volume-1\n",
      "volume-10\n",
      "volume-100\n",
      "volume-101\n",
      "volume-102\n",
      "volume-103\n",
      "volume-104\n",
      "volume-105\n",
      "volume-106\n",
      "volume-107\n",
      "volume-108\n",
      "volume-109\n",
      "volume-11\n",
      "volume-110\n",
      "volume-111\n",
      "volume-112\n",
      "volume-113\n",
      "volume-114\n",
      "volume-115\n",
      "volume-116\n",
      "volume-117\n",
      "volume-118\n",
      "volume-119\n",
      "volume-12\n",
      "volume-120\n",
      "volume-121\n",
      "volume-122\n",
      "volume-123\n",
      "volume-124\n",
      "volume-125\n",
      "volume-126\n",
      "volume-127\n",
      "volume-128\n",
      "volume-129\n",
      "volume-13\n",
      "volume-14\n",
      "volume-15\n",
      "volume-16\n",
      "volume-17\n",
      "volume-18\n",
      "volume-19\n",
      "volume-2\n",
      "volume-20\n",
      "volume-21\n",
      "volume-22\n",
      "volume-23\n",
      "volume-24\n",
      "volume-25\n",
      "volume-26\n",
      "volume-27\n",
      "volume-28\n",
      "volume-29\n",
      "volume-3\n",
      "volume-30\n",
      "volume-31\n",
      "volume-32\n",
      "volume-33\n",
      "volume-34\n",
      "volume-35\n",
      "volume-36\n",
      "volume-37\n",
      "volume-38\n",
      "volume-39\n",
      "volume-4\n",
      "volume-40\n",
      "volume-41\n",
      "volume-42\n",
      "volume-43\n",
      "volume-44\n",
      "volume-45\n",
      "volume-46\n",
      "volume-47\n",
      "volume-48\n",
      "volume-49\n",
      "volume-5\n",
      "volume-50\n",
      "volume-51\n",
      "volume-52\n",
      "volume-53\n",
      "volume-54\n",
      "volume-55\n",
      "volume-56\n",
      "volume-57\n",
      "volume-58\n",
      "volume-59\n",
      "volume-6\n",
      "volume-60\n",
      "volume-61\n",
      "volume-62\n",
      "volume-63\n",
      "volume-64\n",
      "volume-65\n",
      "volume-66\n",
      "volume-67\n",
      "volume-68\n",
      "volume-69\n",
      "volume-7\n",
      "volume-70\n",
      "volume-71\n",
      "volume-72\n",
      "volume-73\n",
      "volume-74\n",
      "volume-75\n",
      "volume-76\n",
      "volume-77\n",
      "volume-78\n",
      "volume-79\n",
      "volume-8\n",
      "volume-80\n",
      "volume-81\n",
      "volume-82\n",
      "volume-83\n",
      "volume-84\n",
      "volume-85\n",
      "volume-86\n",
      "volume-87\n",
      "volume-88\n",
      "volume-89\n",
      "volume-9\n",
      "volume-90\n",
      "volume-91\n",
      "volume-92\n",
      "volume-93\n",
      "volume-94\n",
      "volume-95\n",
      "volume-96\n",
      "volume-97\n",
      "volume-98\n",
      "volume-99\n"
     ]
    }
   ],
   "source": [
    "# #npy를 slice별로 나누어 하나의 list저장\n",
    "# segmentation_list=[]\n",
    "# for file in segmentation_data:\n",
    "#     fname=os.path.basename(file)\n",
    "#     print(fname)\n",
    "#     img_array=np.load(data_path+fname+'.npy')\n",
    "    \n",
    "#     #print(f'img_num: {img_array.shape}')\n",
    "    \n",
    "#     if len(img_array.shape) == 3:\n",
    "#         nx, ny, nz = img_array.shape\n",
    "#         total_slices = img_array.shape[2]\n",
    "#         print(total_slices)\n",
    "#         # iterate through slices\n",
    "#         for current_slice in range(0, total_slices):\n",
    "#             segmentation_list.append(img_array[:,:,current_slice]) \n",
    "# #간 1, 병변 2, 나머지 0\n",
    "\n",
    "\n",
    "volume_list=[]\n",
    "for file in volume_data:\n",
    "    fname=os.path.basename(file)\n",
    "    print(fname)\n",
    "    img_array=np.load(data_path+fname+'.npy')\n",
    "    \n",
    "    #print(f'img_num: {img_array.shape}')\n",
    "    \n",
    "    if len(img_array.shape) == 3:\n",
    "        nx, ny, nz = img_array.shape\n",
    "        total_slices = img_array.shape[2]\n",
    "        # iterate through slices\n",
    "        for current_slice in range(0, total_slices):\n",
    "            volume_list.append(img_array[:,:,current_slice]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #label을 만들어 list에 저장\n",
    "# all_labels = []\n",
    "# for i in segmentation_list:\n",
    "#     if 2 in i:\n",
    "#         all_labels.append(1)\n",
    "#     else:\n",
    "#         all_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(nparray):\n",
    "    # normalize scans to [0,1]\n",
    "    _min = nparray.min()\n",
    "    _max = nparray.max()\n",
    "    nparray = nparray - _min\n",
    "    nparray = nparray / (_max - _min)\n",
    "    return nparray\n",
    "\n",
    "def norm_zscore(nparray):\n",
    "    # normalize 2d scands by mean and standard deviation\n",
    "    mean = nparray.mean()\n",
    "    std = nparray.std()    \n",
    "    nparray = nparray - mean\n",
    "    nparray /= std\n",
    "    return nparray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_MAX = 200\n",
    "WINDOW_MIN = 0\n",
    "GLOBAL_PIXEL_MEAN = 0.1\n",
    "\n",
    "class CustomDataset(Dataset): \n",
    "  def __init__(self,volume_list,all_labels,transforms=None):\n",
    "    self.volume_list=volume_list\n",
    "    self.all_labels=all_labels\n",
    "    self.length=len(all_labels)\n",
    "    self.transforms=transforms\n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    npy=self.volume_list[idx]\n",
    "\n",
    "    npy[npy > WINDOW_MAX] = WINDOW_MAX\n",
    "    npy[npy < WINDOW_MIN] = WINDOW_MIN\n",
    "    \n",
    "    npy = (npy - WINDOW_MIN) / (WINDOW_MAX - WINDOW_MIN)\n",
    "    npy -= GLOBAL_PIXEL_MEAN\n",
    "    \n",
    "    if len(npy.shape)==2:\n",
    "      npy=npy[:,:,np.newaxis].astype(dtype='float32')\n",
    "    \n",
    "    if self.transforms is not None:\n",
    "      npy=self.transforms(npy)\n",
    "    \n",
    "    return{'npy':npy,'label':self.all_labels[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [1, 16, 512, 512]             160\n",
      "       BatchNorm2d-2          [1, 16, 512, 512]              32\n",
      "         LeakyReLU-3          [1, 16, 512, 512]               0\n",
      "         MaxPool2d-4          [1, 16, 256, 256]               0\n",
      "            Conv2d-5          [1, 32, 256, 256]           4,640\n",
      "       BatchNorm2d-6          [1, 32, 256, 256]              64\n",
      "         LeakyReLU-7          [1, 32, 256, 256]               0\n",
      "         MaxPool2d-8          [1, 32, 128, 128]               0\n",
      "            Conv2d-9          [1, 64, 128, 128]          18,496\n",
      "      BatchNorm2d-10          [1, 64, 128, 128]             128\n",
      "        LeakyReLU-11          [1, 64, 128, 128]               0\n",
      "        MaxPool2d-12            [1, 64, 64, 64]               0\n",
      "           Conv2d-13           [1, 128, 64, 64]          73,856\n",
      "      BatchNorm2d-14           [1, 128, 64, 64]             256\n",
      "        LeakyReLU-15           [1, 128, 64, 64]               0\n",
      "        MaxPool2d-16           [1, 128, 32, 32]               0\n",
      "           Conv2d-17           [1, 256, 32, 32]         295,168\n",
      "      BatchNorm2d-18           [1, 256, 32, 32]             512\n",
      "        LeakyReLU-19           [1, 256, 32, 32]               0\n",
      "        MaxPool2d-20           [1, 256, 16, 16]               0\n",
      "           Conv2d-21             [1, 2, 16, 16]           4,610\n",
      "      BatchNorm2d-22             [1, 2, 16, 16]               4\n",
      "        LeakyReLU-23             [1, 2, 16, 16]               0\n",
      "AdaptiveAvgPool2d-24               [1, 2, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 397,926\n",
      "Trainable params: 397,926\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.00\n",
      "Forward/backward pass size (MB): 201.51\n",
      "Params size (MB): 1.52\n",
      "Estimated Total Size (MB): 204.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class CustomConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomConvNet, self).__init__() #상속받은 class에 접근하기 위함\n",
    "\n",
    "        self.layer1 = self.conv_module(1, 16) #흑백사진은 inp\n",
    "        self.layer2 = self.conv_module(16, 32)\n",
    "        self.layer3 = self.conv_module(32, 64)\n",
    "        self.layer4 = self.conv_module(64, 128)\n",
    "        self.layer5 = self.conv_module(128, 256)\n",
    "        self.gap = self.global_avg_pool(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.gap(out)\n",
    "        out = out.view(-1, 2)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def conv_module(self, in_num, out_num):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_num, out_num, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_num),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "    def global_avg_pool(self, in_num, out_num):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_num, out_num, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_num),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1,1)))\n",
    "        \n",
    "model=CustomConvNet()\n",
    "torchsummary.summary(model.cuda(),input_size=(1,512,512),batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([transforms.ToTensor()\n",
    "                                       ])\n",
    "transforms_test = transforms.Compose([transforms.ToTensor()\n",
    "                                       ])\n",
    "\n",
    "hyper_param_epoch=50\n",
    "hyper_param_batch=32\n",
    "hyper_param_learning_rate=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_train, vol_valid, lab_train, lab_valid = train_test_split(volume_list, all_labels, test_size=0.3, shuffle=True, stratify=all_labels, random_state=34)\n",
    "train_dataset=CustomDataset(volume_list=vol_train, all_labels=lab_train,transforms=transforms_train)\n",
    "test_dataset=CustomDataset(volume_list=vol_valid,all_labels=lab_valid,transforms=transforms_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=hyper_param_batch, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=hyper_param_batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 / 1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device,\"/\" ,torch.cuda.device_count())\n",
    "\n",
    "custom_model=CustomConvNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(custom_model.parameters(), lr=hyper_param_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50],i_batch=486 Loss: 0.6047\n",
      "Time: 53.23007273674011sec\n",
      "Epoch [2/50],i_batch=486 Loss: 0.5139\n",
      "Time: 53.55405402183533sec\n",
      "Epoch [3/50],i_batch=486 Loss: 0.4745\n",
      "Time: 53.7421178817749sec\n",
      "Epoch [4/50],i_batch=486 Loss: 0.5293\n",
      "Time: 53.87000298500061sec\n",
      "Epoch [5/50],i_batch=486 Loss: 0.4741\n",
      "Time: 53.942797899246216sec\n",
      "Epoch [6/50],i_batch=486 Loss: 0.4325\n",
      "Time: 53.95321702957153sec\n",
      "Epoch [7/50],i_batch=486 Loss: 0.4161\n",
      "Time: 53.94296622276306sec\n",
      "Epoch [8/50],i_batch=486 Loss: 0.3957\n",
      "Time: 53.91041135787964sec\n",
      "Epoch [9/50],i_batch=486 Loss: 0.3790\n",
      "Time: 54.00072169303894sec\n",
      "Epoch [10/50],i_batch=486 Loss: 0.3516\n",
      "Time: 53.94689989089966sec\n",
      "Epoch [11/50],i_batch=486 Loss: 0.3445\n",
      "Time: 53.923327684402466sec\n",
      "Epoch [12/50],i_batch=486 Loss: 0.3407\n",
      "Time: 53.91600036621094sec\n",
      "Epoch [13/50],i_batch=486 Loss: 0.2793\n",
      "Time: 53.92257785797119sec\n",
      "Epoch [14/50],i_batch=486 Loss: 0.3464\n",
      "Time: 53.90531635284424sec\n",
      "Epoch [15/50],i_batch=486 Loss: 0.2958\n",
      "Time: 53.920103311538696sec\n",
      "Epoch [16/50],i_batch=486 Loss: 0.2871\n",
      "Time: 53.905312299728394sec\n",
      "Epoch [17/50],i_batch=486 Loss: 0.2419\n",
      "Time: 53.924214363098145sec\n",
      "Epoch [18/50],i_batch=486 Loss: 0.2511\n",
      "Time: 53.9416561126709sec\n",
      "Epoch [19/50],i_batch=486 Loss: 0.2102\n",
      "Time: 53.987430572509766sec\n",
      "Epoch [20/50],i_batch=486 Loss: 0.2156\n",
      "Time: 53.94243121147156sec\n",
      "Epoch [21/50],i_batch=486 Loss: 0.2160\n",
      "Time: 53.92962455749512sec\n",
      "Epoch [22/50],i_batch=486 Loss: 0.1798\n",
      "Time: 53.93503928184509sec\n",
      "Epoch [23/50],i_batch=486 Loss: 0.1619\n",
      "Time: 56.046884298324585sec\n",
      "Epoch [24/50],i_batch=486 Loss: 0.1533\n",
      "Time: 86.30187106132507sec\n",
      "Epoch [25/50],i_batch=486 Loss: 0.1617\n",
      "Time: 83.39546751976013sec\n",
      "Epoch [26/50],i_batch=486 Loss: 0.1372\n",
      "Time: 58.92704701423645sec\n",
      "Epoch [27/50],i_batch=486 Loss: 0.1664\n",
      "Time: 63.7029447555542sec\n",
      "Epoch [28/50],i_batch=486 Loss: 0.2049\n",
      "Time: 62.750577211380005sec\n",
      "Epoch [29/50],i_batch=486 Loss: 0.1056\n",
      "Time: 65.50375127792358sec\n",
      "Epoch [30/50],i_batch=486 Loss: 0.1157\n",
      "Time: 61.69965982437134sec\n",
      "Epoch [31/50],i_batch=486 Loss: 0.1919\n",
      "Time: 61.48735165596008sec\n",
      "Epoch [32/50],i_batch=486 Loss: 0.1119\n",
      "Time: 59.994526863098145sec\n",
      "Epoch [33/50],i_batch=486 Loss: 0.0833\n",
      "Time: 59.87358856201172sec\n",
      "Epoch [34/50],i_batch=486 Loss: 0.1063\n",
      "Time: 60.217130184173584sec\n",
      "Epoch [35/50],i_batch=486 Loss: 0.1033\n",
      "Time: 61.06262183189392sec\n",
      "Epoch [36/50],i_batch=486 Loss: 0.0996\n",
      "Time: 61.38403820991516sec\n",
      "Epoch [37/50],i_batch=486 Loss: 0.0890\n",
      "Time: 60.30957293510437sec\n",
      "Epoch [38/50],i_batch=486 Loss: 0.0777\n",
      "Time: 61.05361342430115sec\n",
      "Epoch [39/50],i_batch=486 Loss: 0.0616\n",
      "Time: 62.45812153816223sec\n",
      "Epoch [40/50],i_batch=486 Loss: 0.0675\n",
      "Time: 60.802085638046265sec\n",
      "Epoch [41/50],i_batch=486 Loss: 0.0556\n",
      "Time: 57.56062459945679sec\n",
      "Epoch [42/50],i_batch=486 Loss: 0.0607\n",
      "Time: 56.843141078948975sec\n",
      "Epoch [43/50],i_batch=486 Loss: 0.0825\n",
      "Time: 56.35386085510254sec\n",
      "Epoch [44/50],i_batch=486 Loss: 0.0533\n",
      "Time: 58.271618604660034sec\n",
      "Epoch [45/50],i_batch=486 Loss: 0.0536\n",
      "Time: 54.829245805740356sec\n",
      "Epoch [46/50],i_batch=486 Loss: 0.0609\n",
      "Time: 55.10484051704407sec\n",
      "Epoch [47/50],i_batch=486 Loss: 0.0765\n",
      "Time: 56.13484072685242sec\n",
      "Epoch [48/50],i_batch=486 Loss: 0.0624\n",
      "Time: 56.95255732536316sec\n",
      "Epoch [49/50],i_batch=486 Loss: 0.0459\n",
      "Time: 62.82460117340088sec\n",
      "Epoch [50/50],i_batch=486 Loss: 0.1194\n",
      "Time: 59.798479318618774sec\n"
     ]
    }
   ],
   "source": [
    "loss_value=1\n",
    "start=time.time()\n",
    "custom_model.train()\n",
    "for e in range(hyper_param_epoch):\n",
    "        for i_batch, item in enumerate(train_loader):\n",
    "                npys = item['npy'].to(device)\n",
    "                labels = item['label'].to(device)\n",
    "                #print(npys)\n",
    "                # Forward pass\n",
    "                outputs =custom_model(npys)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    " \n",
    "\n",
    "        print('Epoch [{}/{}],i_batch={} Loss: {:.4f}'\n",
    "                                        .format(e + 1, hyper_param_epoch, i_batch+1, loss.item()))\n",
    "        print(\"Time: {}sec\".format(time.time()-start))\n",
    "        start=time.time()\n",
    "        if loss_value>loss.item():\n",
    "                loss_value=loss.item()\n",
    "                torch.save({\n",
    "                'epoch': e,\n",
    "                'model_state_dict': custom_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                }, '/home/sumins/workspace/model_check/model_best.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 6663 test images: 92.9611286207414 %\n"
     ]
    }
   ],
   "source": [
    "true_label=[]\n",
    "pred_label=[]\n",
    "custom_model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for item in test_loader:\n",
    "        npys = item['npy'].to(device)\n",
    "        labels = item['label'].to(device)\n",
    "        \n",
    "        outputs = custom_model(npys)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        true_label.extend(labels)\n",
    "        pred_label.extend(predicted)\n",
    "        total += len(labels)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('Test Accuracy of the model on the {} test images: {} %'.format(total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      4566\n",
      "           1       0.82      1.00      0.90      2097\n",
      "\n",
      "    accuracy                           0.93      6663\n",
      "   macro avg       0.91      0.95      0.92      6663\n",
      "weighted avg       0.94      0.93      0.93      6663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true_labels=torch.tensor(true_label)\n",
    "true_labels=true_labels.tolist()\n",
    "pred_labels=torch.tensor(pred_label)\n",
    "pred_labels=pred_labels.tolist()\n",
    "print(classification_report(true_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0459, device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomConvNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer5): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (gap): Sequential(\n",
       "    (0): Conv2d(256, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "\n",
    "model=CustomConvNet().to(device)\n",
    "optimizer = torch.optim.Adam(custom_model.parameters(), lr=hyper_param_learning_rate)\n",
    "\n",
    "checkpoint = torch.load('/home/sumins/workspace/model_check/model_best.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "print(loss)\n",
    "model.eval()\n",
    "# with torch.no_grad():\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for item in test_loader:\n",
    "#         npys = item['npy'].to(device)\n",
    "#         labels = item['label'].to(device)\n",
    "        \n",
    "#         outputs = model(npys)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += len(labels)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "        \n",
    "#     print('Test Accuracy of the model on the {} test images: {} %'.format(total, 100 * correct / total))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
