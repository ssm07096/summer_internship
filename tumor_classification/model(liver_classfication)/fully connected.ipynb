{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import nibabel as nib\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchsummary\n",
    "from torchvision import transforms\n",
    "import time\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일이름 sort해서 list저장\n",
    "data_path='/disk1/data_liverbound_noclip/'\n",
    "name_list=os.listdir(data_path)\n",
    "\n",
    "segmentation_data = [files[:-4] for files in name_list if files.startswith('segmentation')]\n",
    "segmentation_data=list(set(segmentation_data))\n",
    "segmentation_data.sort()\n",
    "seg_data_test=[]\n",
    "for i in range(30,45):\n",
    "    seg_data_test.append(segmentation_data.pop(i))\n",
    "\n",
    "volume_data=[files[:-4] for files in name_list if files.startswith('volume')]\n",
    "volume_data=list(set(volume_data))\n",
    "volume_data.sort()\n",
    "vol_data_test=[]\n",
    "for i in range(30,45):\n",
    "    vol_data_test.append(volume_data.pop(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmentation-0\n",
      "segmentation-1\n",
      "segmentation-10\n",
      "segmentation-100\n",
      "segmentation-101\n",
      "segmentation-102\n",
      "segmentation-103\n",
      "segmentation-104\n",
      "segmentation-105\n",
      "segmentation-106\n",
      "segmentation-107\n",
      "segmentation-108\n",
      "segmentation-109\n",
      "segmentation-11\n",
      "segmentation-110\n",
      "segmentation-111\n",
      "segmentation-112\n",
      "segmentation-113\n",
      "segmentation-114\n",
      "segmentation-115\n",
      "segmentation-116\n",
      "segmentation-117\n",
      "segmentation-118\n",
      "segmentation-119\n",
      "segmentation-12\n",
      "segmentation-120\n",
      "segmentation-121\n",
      "segmentation-122\n",
      "segmentation-123\n",
      "segmentation-124\n",
      "segmentation-126\n",
      "segmentation-128\n",
      "segmentation-13\n",
      "segmentation-15\n",
      "segmentation-17\n",
      "segmentation-19\n",
      "segmentation-20\n",
      "segmentation-22\n",
      "segmentation-24\n",
      "segmentation-26\n",
      "segmentation-28\n",
      "segmentation-3\n",
      "segmentation-31\n",
      "segmentation-33\n",
      "segmentation-35\n",
      "segmentation-36\n",
      "segmentation-37\n",
      "segmentation-38\n",
      "segmentation-39\n",
      "segmentation-4\n",
      "segmentation-40\n",
      "segmentation-41\n",
      "segmentation-42\n",
      "segmentation-43\n",
      "segmentation-44\n",
      "segmentation-45\n",
      "segmentation-46\n",
      "segmentation-47\n",
      "segmentation-48\n",
      "segmentation-49\n",
      "segmentation-5\n",
      "segmentation-50\n",
      "segmentation-51\n",
      "segmentation-52\n",
      "segmentation-53\n",
      "segmentation-54\n",
      "segmentation-55\n",
      "segmentation-56\n",
      "segmentation-57\n",
      "segmentation-58\n",
      "segmentation-59\n",
      "segmentation-6\n",
      "segmentation-60\n",
      "segmentation-61\n",
      "segmentation-62\n",
      "segmentation-63\n",
      "segmentation-64\n",
      "segmentation-65\n",
      "segmentation-66\n",
      "segmentation-67\n",
      "segmentation-68\n",
      "segmentation-69\n",
      "segmentation-7\n",
      "segmentation-70\n",
      "segmentation-71\n",
      "segmentation-72\n",
      "segmentation-73\n",
      "segmentation-74\n",
      "segmentation-75\n",
      "segmentation-76\n",
      "segmentation-77\n",
      "segmentation-78\n",
      "segmentation-79\n",
      "segmentation-8\n",
      "segmentation-80\n",
      "segmentation-81\n",
      "segmentation-82\n",
      "segmentation-83\n",
      "segmentation-84\n",
      "segmentation-85\n",
      "segmentation-86\n",
      "segmentation-87\n",
      "segmentation-88\n",
      "segmentation-89\n",
      "segmentation-9\n",
      "segmentation-90\n",
      "segmentation-91\n",
      "segmentation-92\n",
      "segmentation-93\n",
      "segmentation-94\n",
      "segmentation-95\n",
      "segmentation-96\n",
      "segmentation-97\n",
      "segmentation-98\n",
      "segmentation-99\n",
      "segmentation-125\n",
      "133\n",
      "segmentation-127\n",
      "270\n",
      "segmentation-129\n",
      "325\n",
      "segmentation-14\n",
      "164\n",
      "segmentation-16\n",
      "222\n",
      "segmentation-18\n",
      "224\n",
      "segmentation-2\n",
      "164\n",
      "segmentation-21\n",
      "191\n",
      "segmentation-23\n",
      "137\n",
      "segmentation-25\n",
      "277\n",
      "segmentation-27\n",
      "272\n",
      "segmentation-29\n",
      "135\n",
      "segmentation-30\n",
      "146\n",
      "segmentation-32\n",
      "128\n",
      "segmentation-34\n",
      "109\n",
      "volume-0\n",
      "volume-1\n",
      "volume-10\n",
      "volume-100\n",
      "volume-101\n",
      "volume-102\n",
      "volume-103\n",
      "volume-104\n",
      "volume-105\n",
      "volume-106\n",
      "volume-107\n",
      "volume-108\n",
      "volume-109\n",
      "volume-11\n",
      "volume-110\n",
      "volume-111\n",
      "volume-112\n",
      "volume-113\n",
      "volume-114\n",
      "volume-115\n",
      "volume-116\n",
      "volume-117\n",
      "volume-118\n",
      "volume-119\n",
      "volume-12\n",
      "volume-120\n",
      "volume-121\n",
      "volume-122\n",
      "volume-123\n",
      "volume-124\n",
      "volume-126\n",
      "volume-128\n",
      "volume-13\n",
      "volume-15\n",
      "volume-17\n",
      "volume-19\n",
      "volume-20\n",
      "volume-22\n",
      "volume-24\n",
      "volume-26\n",
      "volume-28\n",
      "volume-3\n",
      "volume-31\n",
      "volume-33\n",
      "volume-35\n",
      "volume-36\n",
      "volume-37\n",
      "volume-38\n",
      "volume-39\n",
      "volume-4\n",
      "volume-40\n",
      "volume-41\n",
      "volume-42\n",
      "volume-43\n",
      "volume-44\n",
      "volume-45\n",
      "volume-46\n",
      "volume-47\n",
      "volume-48\n",
      "volume-49\n",
      "volume-5\n",
      "volume-50\n",
      "volume-51\n",
      "volume-52\n",
      "volume-53\n",
      "volume-54\n",
      "volume-55\n",
      "volume-56\n",
      "volume-57\n",
      "volume-58\n",
      "volume-59\n",
      "volume-6\n",
      "volume-60\n",
      "volume-61\n",
      "volume-62\n",
      "volume-63\n",
      "volume-64\n",
      "volume-65\n",
      "volume-66\n",
      "volume-67\n",
      "volume-68\n",
      "volume-69\n",
      "volume-7\n",
      "volume-70\n",
      "volume-71\n",
      "volume-72\n",
      "volume-73\n",
      "volume-74\n",
      "volume-75\n",
      "volume-76\n",
      "volume-77\n",
      "volume-78\n",
      "volume-79\n",
      "volume-8\n",
      "volume-80\n",
      "volume-81\n",
      "volume-82\n",
      "volume-83\n",
      "volume-84\n",
      "volume-85\n",
      "volume-86\n",
      "volume-87\n",
      "volume-88\n",
      "volume-89\n",
      "volume-9\n",
      "volume-90\n",
      "volume-91\n",
      "volume-92\n",
      "volume-93\n",
      "volume-94\n",
      "volume-95\n",
      "volume-96\n",
      "volume-97\n",
      "volume-98\n",
      "volume-99\n",
      "volume-125\n",
      "volume-127\n",
      "volume-129\n",
      "volume-14\n",
      "volume-16\n",
      "volume-18\n",
      "volume-2\n",
      "volume-21\n",
      "volume-23\n",
      "volume-25\n",
      "volume-27\n",
      "volume-29\n",
      "volume-30\n",
      "volume-32\n",
      "volume-34\n"
     ]
    }
   ],
   "source": [
    "#npy를 slice별로 나누어 하나의 list저장\n",
    "seg_list_train=[]\n",
    "seg_list_test=[]\n",
    "for file in segmentation_data:\n",
    "    fname=os.path.basename(file)\n",
    "    print(fname)\n",
    "    img_array=np.load(data_path+fname+'.npy')\n",
    "    \n",
    "    #print(f'img_num: {img_array.shape}')\n",
    "    \n",
    "    if len(img_array.shape) == 3:\n",
    "        nx, ny, nz = img_array.shape\n",
    "        total_slices = img_array.shape[2]\n",
    "        #print(total_slices)\n",
    "        # iterate through slices\n",
    "        for current_slice in range(0, total_slices):\n",
    "            seg_list_train.append(img_array[:,:,current_slice]) \n",
    "\n",
    "for file in seg_data_test:\n",
    "    fname=os.path.basename(file)\n",
    "    print(fname)\n",
    "    img_array=np.load(data_path+fname+'.npy')\n",
    "    \n",
    "    #print(f'img_num: {img_array.shape}')\n",
    "    \n",
    "    if len(img_array.shape) == 3:\n",
    "        nx, ny, nz = img_array.shape\n",
    "        total_slices = img_array.shape[2]\n",
    "        print(total_slices)\n",
    "        # iterate through slices\n",
    "        for current_slice in range(0, total_slices):\n",
    "            seg_list_test.append(img_array[:,:,current_slice]) \n",
    "#간 1, 병변 2, 나머지 0\n",
    "\n",
    "\n",
    "vol_list_train=[]\n",
    "vol_list_test=[]\n",
    "for file in volume_data:\n",
    "    fname=os.path.basename(file)\n",
    "    print(fname)\n",
    "    img_array=np.load(data_path+fname+'.npy')\n",
    "    \n",
    "    #print(f'img_num: {img_array.shape}')\n",
    "    \n",
    "    if len(img_array.shape) == 3:\n",
    "        nx, ny, nz = img_array.shape\n",
    "        total_slices = img_array.shape[2]\n",
    "        # iterate through slices\n",
    "        for current_slice in range(0, total_slices):\n",
    "            vol_list_train.append(img_array[:,:,current_slice]) \n",
    "            \n",
    "for file in vol_data_test:\n",
    "    fname=os.path.basename(file)\n",
    "    print(fname)\n",
    "    img_array=np.load(data_path+fname+'.npy')\n",
    "    \n",
    "    #print(f'img_num: {img_array.shape}')\n",
    "    \n",
    "    if len(img_array.shape) == 3:\n",
    "        nx, ny, nz = img_array.shape\n",
    "        total_slices = img_array.shape[2]\n",
    "        # iterate through slices\n",
    "        for current_slice in range(0, total_slices):\n",
    "            vol_list_test.append(img_array[:,:,current_slice]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label을 만들어 list에 저장\n",
    "labels_train = []\n",
    "labels_test=[]\n",
    "for i in seg_list_test:\n",
    "    if 2 in i:\n",
    "        labels_test.append(1)\n",
    "    else:\n",
    "        labels_test.append(0)\n",
    "        \n",
    "for i in seg_list_train:\n",
    "    if 2 in i:\n",
    "        labels_train.append(1)\n",
    "    else:\n",
    "        labels_train.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_MAX = 200\n",
    "WINDOW_MIN = 0\n",
    "GLOBAL_PIXEL_MEAN = 0.1\n",
    "\n",
    "class CustomDataset(Dataset): \n",
    "  def __init__(self,volume_list,all_labels,transforms=None):\n",
    "    self.volume_list=volume_list\n",
    "    self.all_labels=all_labels\n",
    "    self.length=len(all_labels)\n",
    "    self.transforms=transforms\n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    npy=self.volume_list[idx]\n",
    "\n",
    "    npy[npy > WINDOW_MAX] = WINDOW_MAX\n",
    "    npy[npy < WINDOW_MIN] = WINDOW_MIN\n",
    "    \n",
    "    npy = (npy - WINDOW_MIN) / (WINDOW_MAX - WINDOW_MIN)\n",
    "    npy -= GLOBAL_PIXEL_MEAN\n",
    "    \n",
    "    if len(npy.shape)==2:\n",
    "      npy=npy[:,:,np.newaxis].astype(dtype='float32')\n",
    "    \n",
    "    if self.transforms is not None:\n",
    "      npy=self.transforms(npy)\n",
    "    \n",
    "    return{'npy':npy,'label':self.all_labels[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_param_epoch=100\n",
    "hyper_param_batch=16\n",
    "hyper_param_learning_rate=0.0001\n",
    "from torch import nn\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "    \t# super함수는 CNN class의 부모 class인 nn.Module을 초기화\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # batch_size = 1\n",
    "        self.layer = nn.Sequential(\n",
    "            # [1,1,512,512] -> [1,16,508,508]\n",
    "            nn.Conv2d(in_channels=1,out_channels=16,kernel_size=5),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # [1,16,508,508] -> [1,32,504,504]\n",
    "            nn.Conv2d(in_channels=16,out_channels=32,kernel_size=5),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            # [1,32,504,504] -> [1,32,10,252,252]\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            \n",
    "            # [1,32,252,252] -> [1,64,248,248]\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            # [1,64,248,248] -> [1,64,124,124]\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2), \n",
    "\n",
    "            # [1,64,124,124] -> [1,128,120,120]\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            # [1,128,120,120] -> [1,128,60,60]\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "                \n",
    "            # [1,128,60,60] -> [1,256,56,56]\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            # [1,256,56,56] -> [1,256,28,28]\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)         \n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "        \t# [256*28*28]-->[100]\n",
    "            nn.Linear(256*28*28,100),                                              \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,32),                                              \n",
    "            nn.ReLU(),\n",
    "            # [100,100] -> [100,10]\n",
    "            nn.Linear(32,2)                                                   \n",
    "        )       \n",
    "        \n",
    "    def forward(self,x):\n",
    "    \t# self.layer에 정의한 연산 수행\n",
    "        \n",
    "        out = self.layer(x)\n",
    "        #print(out.shape)\n",
    "        # view 함수를 이용해 텐서의 형태를 [100,나머지]로 변환\n",
    "        out = out.view(hyper_param_batch,-1)\n",
    "        #print(out.shape)\n",
    "        # self.fc_layer 정의한 연산 수행    \n",
    "        out = self.fc_layer(out)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([transforms.ToTensor()\n",
    "                                       ])\n",
    "transforms_test = transforms.Compose([transforms.ToTensor()\n",
    "                                       ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2897"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vol_train, vol_valid, lab_train, lab_valid = train_test_split(volume_list, all_labels, test_size=0.3, shuffle=True, stratify=all_labels, random_state=34)\n",
    "train_dataset=CustomDataset(volume_list=vol_list_train, all_labels=labels_train,transforms=transforms_train)\n",
    "test_dataset=CustomDataset(volume_list=vol_list_test,all_labels=labels_test,transforms=transforms_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=hyper_param_batch, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=hyper_param_batch, shuffle=True)\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 / 1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device,\"/\" ,torch.cuda.device_count())\n",
    "\n",
    "custom_model=CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(custom_model.parameters(), lr=hyper_param_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loss(model):\n",
    "    total_loss=0\n",
    "    for i_batch, item in enumerate(test_loader):\n",
    "        npys = item['npy'].to(device)\n",
    "        labels = item['label'].to(device)\n",
    "        if(len(labels)!=hyper_param_batch):\n",
    "            break\n",
    "        outputs =model(npys)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_loss+=loss.item()\n",
    "    return total_loss/(i_batch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100],i_batch=1207 ,Train_Loss: 0.0079,Valid_loss: 1.0715\n",
      "Time: 1199.221314907074sec\n",
      "Epoch [2/100],i_batch=1207 ,Train_Loss: 0.0110,Valid_loss: 1.0255\n",
      "Time: 801.7111701965332sec\n",
      "Epoch [3/100],i_batch=1207 ,Train_Loss: 0.0154,Valid_loss: 1.2692\n",
      "Time: 845.3068540096283sec\n",
      "Epoch [4/100],i_batch=1207 ,Train_Loss: 0.1516,Valid_loss: 1.1026\n",
      "Time: 1550.6968653202057sec\n",
      "Epoch [5/100],i_batch=1207 ,Train_Loss: 0.0143,Valid_loss: 1.5220\n",
      "Time: 1913.5907008647919sec\n",
      "Epoch [6/100],i_batch=1207 ,Train_Loss: 0.0163,Valid_loss: 1.3398\n",
      "Time: 1880.5412130355835sec\n",
      "Epoch [7/100],i_batch=1207 ,Train_Loss: 0.0499,Valid_loss: 1.4815\n",
      "Time: 1725.383761882782sec\n",
      "Epoch [8/100],i_batch=1207 ,Train_Loss: 0.1692,Valid_loss: 1.2848\n",
      "Time: 1424.0342373847961sec\n",
      "Epoch [9/100],i_batch=1207 ,Train_Loss: 0.1250,Valid_loss: 1.3933\n",
      "Time: 1419.6251165866852sec\n",
      "Epoch [10/100],i_batch=1207 ,Train_Loss: 0.0034,Valid_loss: 1.3746\n",
      "Time: 1424.061653137207sec\n",
      "Epoch [11/100],i_batch=1207 ,Train_Loss: 0.0067,Valid_loss: 1.7967\n",
      "Time: 1381.8341672420502sec\n",
      "Epoch [12/100],i_batch=1207 ,Train_Loss: 0.0004,Valid_loss: 1.7123\n",
      "Time: 1399.2308299541473sec\n",
      "Epoch [13/100],i_batch=1207 ,Train_Loss: 0.0007,Valid_loss: 1.6149\n",
      "Time: 1397.9160842895508sec\n",
      "Epoch [14/100],i_batch=1207 ,Train_Loss: 0.2725,Valid_loss: 1.4965\n",
      "Time: 1394.4728698730469sec\n",
      "Epoch [15/100],i_batch=1207 ,Train_Loss: 0.0017,Valid_loss: 1.6831\n",
      "Time: 1345.0762269496918sec\n",
      "Epoch [16/100],i_batch=1207 ,Train_Loss: 0.0020,Valid_loss: 1.7712\n",
      "Time: 1334.6544144153595sec\n",
      "Epoch [17/100],i_batch=1207 ,Train_Loss: 0.0012,Valid_loss: 1.8632\n",
      "Time: 1384.4370381832123sec\n",
      "Epoch [18/100],i_batch=1207 ,Train_Loss: 0.0060,Valid_loss: 1.8507\n",
      "Time: 1339.3197066783905sec\n",
      "Epoch [19/100],i_batch=1207 ,Train_Loss: 0.0001,Valid_loss: 1.8617\n",
      "Time: 1411.182739019394sec\n",
      "Epoch [20/100],i_batch=1207 ,Train_Loss: 0.0358,Valid_loss: 2.0761\n",
      "Time: 1428.7039976119995sec\n",
      "Epoch [21/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 1.9427\n",
      "Time: 1413.897022485733sec\n",
      "Epoch [22/100],i_batch=1207 ,Train_Loss: 0.0002,Valid_loss: 1.7581\n",
      "Time: 1453.1199939250946sec\n",
      "Epoch [23/100],i_batch=1207 ,Train_Loss: 0.0001,Valid_loss: 1.9172\n",
      "Time: 1450.534569978714sec\n",
      "Epoch [24/100],i_batch=1207 ,Train_Loss: 0.0001,Valid_loss: 1.7585\n",
      "Time: 1315.4890084266663sec\n",
      "Epoch [25/100],i_batch=1207 ,Train_Loss: 0.0006,Valid_loss: 2.1738\n",
      "Time: 1331.0217587947845sec\n",
      "Epoch [26/100],i_batch=1207 ,Train_Loss: 0.0003,Valid_loss: 2.1356\n",
      "Time: 1149.8450679779053sec\n",
      "Epoch [27/100],i_batch=1207 ,Train_Loss: 0.0916,Valid_loss: 2.0966\n",
      "Time: 755.6305866241455sec\n",
      "Epoch [28/100],i_batch=1207 ,Train_Loss: 0.0012,Valid_loss: 1.7151\n",
      "Time: 378.04282999038696sec\n",
      "Epoch [29/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 1.9728\n",
      "Time: 275.78684639930725sec\n",
      "Epoch [30/100],i_batch=1207 ,Train_Loss: 0.0002,Valid_loss: 1.9757\n",
      "Time: 276.22543382644653sec\n",
      "Epoch [31/100],i_batch=1207 ,Train_Loss: 0.0001,Valid_loss: 2.2324\n",
      "Time: 275.74619698524475sec\n",
      "Epoch [32/100],i_batch=1207 ,Train_Loss: 0.0230,Valid_loss: 2.0298\n",
      "Time: 275.99131631851196sec\n",
      "Epoch [33/100],i_batch=1207 ,Train_Loss: 0.0001,Valid_loss: 1.8532\n",
      "Time: 276.6980519294739sec\n",
      "Epoch [34/100],i_batch=1207 ,Train_Loss: 0.0021,Valid_loss: 1.8195\n",
      "Time: 275.78942108154297sec\n",
      "Epoch [35/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.1716\n",
      "Time: 275.2063798904419sec\n",
      "Epoch [36/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.1613\n",
      "Time: 273.7039113044739sec\n",
      "Epoch [37/100],i_batch=1207 ,Train_Loss: 0.0002,Valid_loss: 2.1238\n",
      "Time: 273.3818395137787sec\n",
      "Epoch [38/100],i_batch=1207 ,Train_Loss: 0.0001,Valid_loss: 1.9967\n",
      "Time: 273.36882495880127sec\n",
      "Epoch [39/100],i_batch=1207 ,Train_Loss: 0.0002,Valid_loss: 2.2853\n",
      "Time: 273.3925623893738sec\n",
      "Epoch [40/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.4659\n",
      "Time: 273.40221548080444sec\n",
      "Epoch [41/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.0039\n",
      "Time: 273.4832444190979sec\n",
      "Epoch [42/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.5378\n",
      "Time: 273.32406306266785sec\n",
      "Epoch [43/100],i_batch=1207 ,Train_Loss: 0.0490,Valid_loss: 2.1757\n",
      "Time: 273.42235231399536sec\n",
      "Epoch [44/100],i_batch=1207 ,Train_Loss: 0.0001,Valid_loss: 2.3294\n",
      "Time: 273.22249484062195sec\n",
      "Epoch [45/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.3716\n",
      "Time: 273.28878927230835sec\n",
      "Epoch [46/100],i_batch=1207 ,Train_Loss: 0.0054,Valid_loss: 2.0015\n",
      "Time: 273.12398505210876sec\n",
      "Epoch [47/100],i_batch=1207 ,Train_Loss: 0.0003,Valid_loss: 2.4486\n",
      "Time: 273.2797107696533sec\n",
      "Epoch [48/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.9690\n",
      "Time: 273.3140411376953sec\n",
      "Epoch [49/100],i_batch=1207 ,Train_Loss: 0.0001,Valid_loss: 2.3183\n",
      "Time: 273.49623131752014sec\n",
      "Epoch [50/100],i_batch=1207 ,Train_Loss: 0.0001,Valid_loss: 2.4632\n",
      "Time: 273.41716027259827sec\n",
      "Epoch [51/100],i_batch=1207 ,Train_Loss: 0.0001,Valid_loss: 2.7826\n",
      "Time: 273.4133017063141sec\n",
      "Epoch [52/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.6087\n",
      "Time: 273.43187260627747sec\n",
      "Epoch [53/100],i_batch=1207 ,Train_Loss: 0.0002,Valid_loss: 1.9854\n",
      "Time: 273.3886613845825sec\n",
      "Epoch [54/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.6129\n",
      "Time: 273.3875069618225sec\n",
      "Epoch [55/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.5402\n",
      "Time: 273.371710062027sec\n",
      "Epoch [56/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.8540\n",
      "Time: 273.19644379615784sec\n",
      "Epoch [57/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.4953\n",
      "Time: 273.3093316555023sec\n",
      "Epoch [58/100],i_batch=1207 ,Train_Loss: 0.0001,Valid_loss: 2.5492\n",
      "Time: 273.41227769851685sec\n",
      "Epoch [59/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.8249\n",
      "Time: 273.42437267303467sec\n",
      "Epoch [60/100],i_batch=1207 ,Train_Loss: 0.0004,Valid_loss: 2.0151\n",
      "Time: 273.18517088890076sec\n",
      "Epoch [61/100],i_batch=1207 ,Train_Loss: 0.0001,Valid_loss: 2.6683\n",
      "Time: 273.44770193099976sec\n",
      "Epoch [62/100],i_batch=1207 ,Train_Loss: 0.0002,Valid_loss: 1.6668\n",
      "Time: 273.40155124664307sec\n",
      "Epoch [63/100],i_batch=1207 ,Train_Loss: 0.0001,Valid_loss: 2.6368\n",
      "Time: 273.35564374923706sec\n",
      "Epoch [64/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 3.6765\n",
      "Time: 273.3730905056sec\n",
      "Epoch [65/100],i_batch=1207 ,Train_Loss: 0.0001,Valid_loss: 2.4451\n",
      "Time: 273.30028796195984sec\n",
      "Epoch [66/100],i_batch=1207 ,Train_Loss: 0.0002,Valid_loss: 1.9843\n",
      "Time: 273.2182550430298sec\n",
      "Epoch [67/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.9240\n",
      "Time: 273.33508920669556sec\n",
      "Epoch [68/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.3836\n",
      "Time: 273.3238933086395sec\n",
      "Epoch [69/100],i_batch=1207 ,Train_Loss: 0.0001,Valid_loss: 2.8533\n",
      "Time: 273.50938844680786sec\n",
      "Epoch [70/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.9414\n",
      "Time: 273.295214176178sec\n",
      "Epoch [71/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 3.6012\n",
      "Time: 273.4032099246979sec\n",
      "Epoch [72/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.8747\n",
      "Time: 273.40266466140747sec\n",
      "Epoch [73/100],i_batch=1207 ,Train_Loss: 0.0001,Valid_loss: 2.1548\n",
      "Time: 273.4298839569092sec\n",
      "Epoch [74/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.9153\n",
      "Time: 273.3977828025818sec\n",
      "Epoch [75/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.8756\n",
      "Time: 273.2464351654053sec\n",
      "Epoch [76/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 3.2154\n",
      "Time: 273.35539054870605sec\n",
      "Epoch [77/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 3.4307\n",
      "Time: 273.40694642066956sec\n",
      "Epoch [78/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 3.6344\n",
      "Time: 273.2711148262024sec\n",
      "Epoch [79/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 3.8453\n",
      "Time: 273.28553342819214sec\n",
      "Epoch [80/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 4.0556\n",
      "Time: 273.47031807899475sec\n",
      "Epoch [81/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 4.2687\n",
      "Time: 273.39352226257324sec\n",
      "Epoch [82/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 4.4822\n",
      "Time: 273.3221380710602sec\n",
      "Epoch [83/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 4.7202\n",
      "Time: 273.31146264076233sec\n",
      "Epoch [84/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 4.9439\n",
      "Time: 273.3783447742462sec\n",
      "Epoch [85/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 5.1848\n",
      "Time: 273.402480840683sec\n",
      "Epoch [86/100],i_batch=1207 ,Train_Loss: 0.0002,Valid_loss: 2.5633\n",
      "Time: 273.49495244026184sec\n",
      "Epoch [87/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.9125\n",
      "Time: 273.4713635444641sec\n",
      "Epoch [88/100],i_batch=1207 ,Train_Loss: 0.0022,Valid_loss: 2.6373\n",
      "Time: 273.59315061569214sec\n",
      "Epoch [89/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.8607\n",
      "Time: 273.70376348495483sec\n",
      "Epoch [90/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.9958\n",
      "Time: 273.6183371543884sec\n",
      "Epoch [91/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 3.0733\n",
      "Time: 273.46698808670044sec\n",
      "Epoch [92/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 3.1626\n",
      "Time: 273.70092248916626sec\n",
      "Epoch [93/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 3.0608\n",
      "Time: 273.8226828575134sec\n",
      "Epoch [94/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 2.8872\n",
      "Time: 273.6526176929474sec\n",
      "Epoch [95/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 3.2106\n",
      "Time: 273.8384029865265sec\n",
      "Epoch [96/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 3.5826\n",
      "Time: 273.752810716629sec\n",
      "Epoch [97/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 3.7046\n",
      "Time: 273.6102149486542sec\n",
      "Epoch [98/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 3.8651\n",
      "Time: 273.74151372909546sec\n",
      "Epoch [99/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 3.9929\n",
      "Time: 273.9207446575165sec\n",
      "Epoch [100/100],i_batch=1207 ,Train_Loss: 0.0000,Valid_loss: 4.1654\n",
      "Time: 273.65711212158203sec\n"
     ]
    }
   ],
   "source": [
    "train_loss_history=[]\n",
    "valid_loss_history=[]\n",
    "loss_value=1\n",
    "\n",
    "start=time.time()\n",
    "custom_model.train()\n",
    "for e in range(hyper_param_epoch):\n",
    "    for i_batch, item in enumerate(train_loader):\n",
    "        npys = item['npy'].to(device)\n",
    "        labels = item['label'].to(device)\n",
    "        if(len(labels)!=hyper_param_batch):\n",
    "            break\n",
    "\n",
    "        #print(npys)\n",
    "        # Forward pass\n",
    "        outputs = custom_model(npys)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #if(i_batch+1)%10==0:\n",
    "    val_loss=validation_loss(custom_model)\n",
    "\n",
    "    train_loss_history.append(loss.item())\n",
    "    valid_loss_history.append(val_loss)\n",
    "    \n",
    "\n",
    "    print('Epoch [{}/{}],i_batch={} ,Train_Loss: {:.4f},Valid_loss: {:.4f}'\n",
    "                                    .format(e + 1, hyper_param_epoch, i_batch+1, loss.item(),val_loss))\n",
    "    print(\"Time: {}sec\".format(time.time()-start))\n",
    "    start=time.time()\n",
    "    if loss_value>val_loss:\n",
    "            loss_value=val_loss\n",
    "            torch.save({\n",
    "            'epoch': e,\n",
    "            'model_state_dict': custom_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, '/home/sumins/workspace/model_check/custom_model_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_history)\n",
    "plt.plot(valid_loss_history)\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 2896 test images: 66.29834254143647 %\n"
     ]
    }
   ],
   "source": [
    "custom_model.eval()\n",
    "true_label=[]\n",
    "pred_label=[]\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for item in test_loader:\n",
    "        npys = item['npy'].to(device)\n",
    "        labels = item['label'].to(device)\n",
    "        if(len(labels)!=hyper_param_batch):\n",
    "            break\n",
    "        outputs = custom_model(npys)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        true_label.extend(labels)\n",
    "        pred_label.extend(predicted)\n",
    "\n",
    "        total += len(labels)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('Test Accuracy of the model on the {} test images: {} %'.format(total, 100 * correct / total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "with open(\"valid_loss_history_0721_1.csv\", 'w') as file:\n",
    "  writer = csv.writer(file)\n",
    "  writer.writerow(valid_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "with open(\"train_loss_history_0721_1.csv\", 'w') as file:\n",
    "  writer = csv.writer(file)\n",
    "  writer.writerow(train_loss_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      2154\n",
      "           1       0.36      0.41      0.38       742\n",
      "\n",
      "    accuracy                           0.66      2896\n",
      "   macro avg       0.57      0.58      0.58      2896\n",
      "weighted avg       0.68      0.66      0.67      2896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true_labels=torch.tensor(true_label)\n",
    "true_labels=true_labels.tolist()\n",
    "pred_labels=torch.tensor(pred_label)\n",
    "pred_labels=pred_labels.tolist()\n",
    "print(classification_report(true_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2727055e8302>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyper_param_learning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/sumins/workspace/model_check/model_3.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CNN' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "model=CNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyper_param_learning_rate)\n",
    "\n",
    "checkpoint = torch.load('/home/sumins/workspace/model_check/model_3.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "print(loss)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for item in test_loader:\n",
    "        npys = item['npy'].to(device)\n",
    "        labels = item['label'].to(device)\n",
    "        if(len(labels)!=8):\n",
    "            break\n",
    "        outputs = model(npys)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += len(labels)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('Test Accuracy of the model on the {} test images: {} %'.format(total, 100 * correct / total))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
