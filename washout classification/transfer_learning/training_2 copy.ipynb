{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import nibabel as nib\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchsummary\n",
    "from torchvision import transforms, models\n",
    "import time\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data=np.loadtxt('/home/sumins/workspace/washout classification/min_slice/label_train.txt',dtype=int)\n",
    "label_data=label_data.tolist()\n",
    "label_datat=np.loadtxt('/home/sumins/workspace/washout classification/min_slice/label_test.txt',dtype=int)\n",
    "label_datat=label_datat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='/home/sumins/workspace/washout classification/min_slice/channel4_train.nii'\n",
    "channel4=[]\n",
    "total=nib.load(data_path).get_fdata()\n",
    "totalslice=total.shape[0]  \n",
    "\n",
    "for i in range(0,totalslice):\n",
    "    channel4.append(total[i,:,:,:])\n",
    "\n",
    "\n",
    "data_patht='/home/sumins/workspace/washout classification/min_slice/channel4_test.nii'\n",
    "channel4t=[]\n",
    "totalt=nib.load(data_patht).get_fdata()\n",
    "totalslicet=totalt.shape[0]  \n",
    "\n",
    "for i in range(0,totalslicet):\n",
    "    channel4t.append(totalt[i,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1422\n",
      "363\n"
     ]
    }
   ],
   "source": [
    "print(len(channel4))\n",
    "print(len(channel4t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_MAX = 200\n",
    "WINDOW_MIN = 0\n",
    "GLOBAL_PIXEL_MEAN = 0.1\n",
    "\n",
    "class CustomDataset(Dataset): \n",
    "  def __init__(self,volume_list,all_labels,transforms=None):\n",
    "    self.volume_list=volume_list\n",
    "    self.all_labels=all_labels\n",
    "    self.length=len(all_labels)\n",
    "    self.transforms=transforms\n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    npy=self.volume_list[idx]\n",
    "\n",
    "    npy[npy > WINDOW_MAX] = WINDOW_MAX\n",
    "    npy[npy < WINDOW_MIN] = WINDOW_MIN\n",
    "    \n",
    "    npy = (npy - WINDOW_MIN) / (WINDOW_MAX - WINDOW_MIN)\n",
    "    npy -= GLOBAL_PIXEL_MEAN\n",
    "    \n",
    "    npy=npy.astype(dtype='float32')\n",
    "    if self.transforms is not None:\n",
    "      npy=self.transforms(npy)\n",
    "    \n",
    "    return{'npy':npy,'label':self.all_labels[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "resnet50_pretrained=models.resnet50(pretrained=True)\n",
    "print(resnet50_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiverResnet(nn.Module):\n",
    "    def __init__(self,in_channels=4):\n",
    "        super(LiverResnet,self).__init__()\n",
    "        \n",
    "        #torchvision.models에서 사전훈련된 resnet모델 가져오기\n",
    "        self.model=models.resnet50(pretrained=True)\n",
    "        \n",
    "        #기본채널이 3이기 때문에 liver data set에 맞게 1로 바꿔줌\n",
    "        #원래 resnet의 첫번째 layer\n",
    "        # self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.model.conv1=nn.Conv2d(in_channels,64,kernel_size=7,stride=2,padding=3,bias=False)\n",
    "        \n",
    "        #class수 변경\n",
    "        num_ftrs=self.model.fc.in_features\n",
    "        self.model.fc=nn.Linear(num_ftrs,2)\n",
    "\n",
    "    def forward(self,x):\n",
    "            return self.model(x)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([transforms.ToTensor()\n",
    "                                       ])\n",
    "transforms_test = transforms.Compose([transforms.ToTensor()\n",
    "                                       ])\n",
    "\n",
    "hyper_param_epoch=50\n",
    "hyper_param_batch=4\n",
    "hyper_param_learning_rate=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=CustomDataset(volume_list=channel4, all_labels=label_data,transforms=transforms_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=hyper_param_batch, shuffle=True)\n",
    "test_dataset=CustomDataset(volume_list=channel4t, all_labels=label_datat,transforms=transforms_train)\n",
    "test_loader = DataLoader(test_dataset, batch_size=hyper_param_batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 / 1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device,\"/\" ,torch.cuda.device_count())\n",
    "\n",
    "model=LiverResnet().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'fc.weight', 'fc.bias'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.conv1.weight\n",
      "model.bn1.weight\n",
      "model.bn1.bias\n",
      "model.layer1.0.conv1.weight\n",
      "model.layer1.0.bn1.weight\n",
      "model.layer1.0.bn1.bias\n",
      "model.layer1.0.conv2.weight\n",
      "model.layer1.0.bn2.weight\n",
      "model.layer1.0.bn2.bias\n",
      "model.layer1.0.conv3.weight\n",
      "model.layer1.0.bn3.weight\n",
      "model.layer1.0.bn3.bias\n",
      "model.layer1.0.downsample.0.weight\n",
      "model.layer1.0.downsample.1.weight\n",
      "model.layer1.0.downsample.1.bias\n",
      "model.layer1.1.conv1.weight\n",
      "model.layer1.1.bn1.weight\n",
      "model.layer1.1.bn1.bias\n",
      "model.layer1.1.conv2.weight\n",
      "model.layer1.1.bn2.weight\n",
      "model.layer1.1.bn2.bias\n",
      "model.layer1.1.conv3.weight\n",
      "model.layer1.1.bn3.weight\n",
      "model.layer1.1.bn3.bias\n",
      "model.layer1.2.conv1.weight\n",
      "model.layer1.2.bn1.weight\n",
      "model.layer1.2.bn1.bias\n",
      "model.layer1.2.conv2.weight\n",
      "model.layer1.2.bn2.weight\n",
      "model.layer1.2.bn2.bias\n",
      "model.layer1.2.conv3.weight\n",
      "model.layer1.2.bn3.weight\n",
      "model.layer1.2.bn3.bias\n",
      "model.layer2.0.conv1.weight\n",
      "model.layer2.0.bn1.weight\n",
      "model.layer2.0.bn1.bias\n",
      "model.layer2.0.conv2.weight\n",
      "model.layer2.0.bn2.weight\n",
      "model.layer2.0.bn2.bias\n",
      "model.layer2.0.conv3.weight\n",
      "model.layer2.0.bn3.weight\n",
      "model.layer2.0.bn3.bias\n",
      "model.layer2.0.downsample.0.weight\n",
      "model.layer2.0.downsample.1.weight\n",
      "model.layer2.0.downsample.1.bias\n",
      "model.layer2.1.conv1.weight\n",
      "model.layer2.1.bn1.weight\n",
      "model.layer2.1.bn1.bias\n",
      "model.layer2.1.conv2.weight\n",
      "model.layer2.1.bn2.weight\n",
      "model.layer2.1.bn2.bias\n",
      "model.layer2.1.conv3.weight\n",
      "model.layer2.1.bn3.weight\n",
      "model.layer2.1.bn3.bias\n",
      "model.layer2.2.conv1.weight\n",
      "model.layer2.2.bn1.weight\n",
      "model.layer2.2.bn1.bias\n",
      "model.layer2.2.conv2.weight\n",
      "model.layer2.2.bn2.weight\n",
      "model.layer2.2.bn2.bias\n",
      "model.layer2.2.conv3.weight\n",
      "model.layer2.2.bn3.weight\n",
      "model.layer2.2.bn3.bias\n",
      "model.layer2.3.conv1.weight\n",
      "model.layer2.3.bn1.weight\n",
      "model.layer2.3.bn1.bias\n",
      "model.layer2.3.conv2.weight\n",
      "model.layer2.3.bn2.weight\n",
      "model.layer2.3.bn2.bias\n",
      "model.layer2.3.conv3.weight\n",
      "model.layer2.3.bn3.weight\n",
      "model.layer2.3.bn3.bias\n",
      "model.layer3.0.conv1.weight\n",
      "model.layer3.0.bn1.weight\n",
      "model.layer3.0.bn1.bias\n",
      "model.layer3.0.conv2.weight\n",
      "model.layer3.0.bn2.weight\n",
      "model.layer3.0.bn2.bias\n",
      "model.layer3.0.conv3.weight\n",
      "model.layer3.0.bn3.weight\n",
      "model.layer3.0.bn3.bias\n",
      "model.layer3.0.downsample.0.weight\n",
      "model.layer3.0.downsample.1.weight\n",
      "model.layer3.0.downsample.1.bias\n",
      "model.layer3.1.conv1.weight\n",
      "model.layer3.1.bn1.weight\n",
      "model.layer3.1.bn1.bias\n",
      "model.layer3.1.conv2.weight\n",
      "model.layer3.1.bn2.weight\n",
      "model.layer3.1.bn2.bias\n",
      "model.layer3.1.conv3.weight\n",
      "model.layer3.1.bn3.weight\n",
      "model.layer3.1.bn3.bias\n",
      "model.layer3.2.conv1.weight\n",
      "model.layer3.2.bn1.weight\n",
      "model.layer3.2.bn1.bias\n",
      "model.layer3.2.conv2.weight\n",
      "model.layer3.2.bn2.weight\n",
      "model.layer3.2.bn2.bias\n",
      "model.layer3.2.conv3.weight\n",
      "model.layer3.2.bn3.weight\n",
      "model.layer3.2.bn3.bias\n",
      "model.layer3.3.conv1.weight\n",
      "model.layer3.3.bn1.weight\n",
      "model.layer3.3.bn1.bias\n",
      "model.layer3.3.conv2.weight\n",
      "model.layer3.3.bn2.weight\n",
      "model.layer3.3.bn2.bias\n",
      "model.layer3.3.conv3.weight\n",
      "model.layer3.3.bn3.weight\n",
      "model.layer3.3.bn3.bias\n",
      "model.layer3.4.conv1.weight\n",
      "model.layer3.4.bn1.weight\n",
      "model.layer3.4.bn1.bias\n",
      "model.layer3.4.conv2.weight\n",
      "model.layer3.4.bn2.weight\n",
      "model.layer3.4.bn2.bias\n",
      "model.layer3.4.conv3.weight\n",
      "model.layer3.4.bn3.weight\n",
      "model.layer3.4.bn3.bias\n",
      "model.layer3.5.conv1.weight\n",
      "model.layer3.5.bn1.weight\n",
      "model.layer3.5.bn1.bias\n",
      "model.layer3.5.conv2.weight\n",
      "model.layer3.5.bn2.weight\n",
      "model.layer3.5.bn2.bias\n",
      "model.layer3.5.conv3.weight\n",
      "model.layer3.5.bn3.weight\n",
      "model.layer3.5.bn3.bias\n",
      "model.layer4.0.conv1.weight\n",
      "model.layer4.0.bn1.weight\n",
      "model.layer4.0.bn1.bias\n",
      "model.layer4.0.conv2.weight\n",
      "model.layer4.0.bn2.weight\n",
      "model.layer4.0.bn2.bias\n",
      "model.layer4.0.conv3.weight\n",
      "model.layer4.0.bn3.weight\n",
      "model.layer4.0.bn3.bias\n",
      "model.layer4.0.downsample.0.weight\n",
      "model.layer4.0.downsample.1.weight\n",
      "model.layer4.0.downsample.1.bias\n",
      "model.layer4.1.conv1.weight\n",
      "model.layer4.1.bn1.weight\n",
      "model.layer4.1.bn1.bias\n",
      "model.layer4.1.conv2.weight\n",
      "model.layer4.1.bn2.weight\n",
      "model.layer4.1.bn2.bias\n",
      "model.layer4.1.conv3.weight\n",
      "model.layer4.1.bn3.weight\n",
      "model.layer4.1.bn3.bias\n",
      "model.layer4.2.conv1.weight\n",
      "model.layer4.2.bn1.weight\n",
      "model.layer4.2.bn1.bias\n",
      "model.layer4.2.conv2.weight\n",
      "model.layer4.2.bn2.weight\n",
      "model.layer4.2.bn2.bias\n",
      "model.layer4.2.conv3.weight\n",
      "model.layer4.2.bn3.weight\n",
      "model.layer4.2.bn3.bias\n",
      "model.fc.weight\n",
      "model.fc.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,param in model.model.named_parameters():\n",
    "    if name in ['layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'fc.weight', 'fc.bias']:\n",
    "        param.requires_grad=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad,model.parameters()), lr=hyper_param_learning_rate)\n",
    "checkpoint = torch.load('/home/sumins/workspace/washout classification/model_save/transfer_1.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loss(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss=0\n",
    "    True_pred=0\n",
    "    for i_batch, item in enumerate(test_loader):\n",
    "        npys = item['npy'].to(device)\n",
    "        labels = item['label'].to(device)\n",
    " \n",
    "        outputs =model(npys)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss+=loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += len(labels)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        for k in predicted:\n",
    "            if k==1:\n",
    "                True_pred+=1\n",
    "    model.train()    \n",
    "     \n",
    "    return total_loss/(i_batch+1),100 * correct / total, True_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344\n",
      "Epoch [1/50],i_batch=356 ,Train_Loss: 0.5451,Train_acc: 75.39Valid_loss: 0.7273, Valid_acc: 68.04\n",
      "Time: 398.0995261669159sec\n",
      "185\n",
      "Epoch [2/50],i_batch=356 ,Train_Loss: 0.3812,Train_acc: 82.91Valid_loss: 0.9322, Valid_acc: 51.24\n",
      "Time: 268.2618627548218sec\n",
      "193\n",
      "Epoch [3/50],i_batch=356 ,Train_Loss: 0.1473,Train_acc: 87.69Valid_loss: 0.9138, Valid_acc: 50.69\n",
      "Time: 278.890234708786sec\n",
      "273\n",
      "Epoch [4/50],i_batch=356 ,Train_Loss: 1.4842,Train_acc: 90.51Valid_loss: 1.0772, Valid_acc: 58.40\n",
      "Time: 283.9459125995636sec\n",
      "290\n",
      "Epoch [5/50],i_batch=356 ,Train_Loss: 3.0702,Train_acc: 92.41Valid_loss: 0.9657, Valid_acc: 63.09\n",
      "Time: 285.1948986053467sec\n",
      "288\n",
      "Epoch [6/50],i_batch=356 ,Train_Loss: 0.0050,Train_acc: 94.16Valid_loss: 0.9770, Valid_acc: 63.64\n",
      "Time: 279.7242398262024sec\n",
      "238\n",
      "Epoch [7/50],i_batch=356 ,Train_Loss: 0.0386,Train_acc: 96.20Valid_loss: 1.3318, Valid_acc: 51.52\n",
      "Time: 275.4696133136749sec\n",
      "186\n",
      "Epoch [8/50],i_batch=356 ,Train_Loss: 0.8770,Train_acc: 96.91Valid_loss: 1.7608, Valid_acc: 46.01\n",
      "Time: 275.40538692474365sec\n",
      "335\n",
      "Epoch [9/50],i_batch=356 ,Train_Loss: 0.1564,Train_acc: 97.61Valid_loss: 1.8910, Valid_acc: 68.32\n",
      "Time: 280.19973826408386sec\n",
      "209\n",
      "Epoch [10/50],i_batch=356 ,Train_Loss: 0.0304,Train_acc: 96.84Valid_loss: 1.1790, Valid_acc: 56.20\n",
      "Time: 295.1500012874603sec\n",
      "259\n",
      "Epoch [11/50],i_batch=356 ,Train_Loss: 0.0108,Train_acc: 98.31Valid_loss: 1.3736, Valid_acc: 57.85\n",
      "Time: 281.9106824398041sec\n",
      "301\n",
      "Epoch [12/50],i_batch=356 ,Train_Loss: 0.0163,Train_acc: 97.82Valid_loss: 1.5086, Valid_acc: 63.91\n",
      "Time: 281.37854838371277sec\n",
      "276\n",
      "Epoch [13/50],i_batch=356 ,Train_Loss: 0.0019,Train_acc: 97.68Valid_loss: 1.5091, Valid_acc: 60.88\n",
      "Time: 286.3175039291382sec\n",
      "265\n",
      "Epoch [14/50],i_batch=356 ,Train_Loss: 0.0011,Train_acc: 99.23Valid_loss: 1.1571, Valid_acc: 66.12\n",
      "Time: 294.57380867004395sec\n",
      "237\n",
      "Epoch [15/50],i_batch=356 ,Train_Loss: 0.0006,Train_acc: 98.66Valid_loss: 1.3762, Valid_acc: 60.06\n",
      "Time: 282.78876066207886sec\n",
      "44\n",
      "Epoch [16/50],i_batch=356 ,Train_Loss: 0.0001,Train_acc: 98.38Valid_loss: 3.3972, Valid_acc: 37.19\n",
      "Time: 278.42547392845154sec\n",
      "203\n",
      "Epoch [17/50],i_batch=356 ,Train_Loss: 0.0048,Train_acc: 98.52Valid_loss: 1.3266, Valid_acc: 52.89\n",
      "Time: 285.01498794555664sec\n",
      "195\n",
      "Epoch [18/50],i_batch=356 ,Train_Loss: 0.0077,Train_acc: 99.16Valid_loss: 1.4651, Valid_acc: 54.55\n",
      "Time: 283.19224739074707sec\n",
      "267\n",
      "Epoch [19/50],i_batch=356 ,Train_Loss: 0.0025,Train_acc: 99.30Valid_loss: 1.4779, Valid_acc: 58.95\n",
      "Time: 274.7624669075012sec\n",
      "61\n",
      "Epoch [20/50],i_batch=356 ,Train_Loss: 0.0001,Train_acc: 99.51Valid_loss: 2.7357, Valid_acc: 36.36\n",
      "Time: 278.65837502479553sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9228c9beb4d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mcorrect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0mnpys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'npy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-102b9210f375>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mnpy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnpy\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mWINDOW_MAX\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWINDOW_MAX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mnpy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnpy\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mWINDOW_MIN\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWINDOW_MIN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mnpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnpy\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mWINDOW_MIN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mWINDOW_MAX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mWINDOW_MIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/memmap.py\u001b[0m in \u001b[0;36m__array_wrap__\u001b[0;34m(self, arr, context)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_value=1\n",
    "start=time.time()\n",
    "model.train()\n",
    "train_loss_history=[]\n",
    "valid_loss_history=[]\n",
    "val_loss=0\n",
    "acc=50\n",
    "for e in range(hyper_param_epoch):\n",
    "        correct=0\n",
    "        total=0\n",
    "        for i_batch, item in enumerate(train_loader):\n",
    "                npys = item['npy'].to(device)\n",
    "                labels = item['label'].to(device)\n",
    "                #print(npys)\n",
    "                # Forward pass\n",
    "                outputs =model(npys)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += len(labels)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "        val_loss,val_accuracy, True_predict=validation_loss(model)\n",
    "        print(True_predict)\n",
    "        train_loss_history.append(loss.item())\n",
    "        valid_loss_history.append(val_loss)\n",
    "        print('Epoch [{}/{}],i_batch={} ,Train_Loss: {:.4f},Train_acc: {:.2f}Valid_loss: {:.4f}, Valid_acc: {:.2f}'\n",
    "                                        .format(e + 1, hyper_param_epoch, i_batch+1, loss.item(), 100*correct/total,val_loss, val_accuracy))\n",
    "        print(\"Time: {}sec\".format(time.time()-start))\n",
    "        start=time.time()\n",
    "        if loss_value>val_loss:\n",
    "                loss_value=val_loss\n",
    "                torch.save({\n",
    "                'epoch': e,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss.item(),\n",
    "                }, '/home/sumins/workspace/washout classification/model_save/transfer_second_freeze.pth')\n",
    "        if val_accuracy>acc:\n",
    "                acc=val_accuracy\n",
    "                torch.save({\n",
    "                'epoch': e,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss.item(),\n",
    "                }, '/home/sumins/workspace/washout classification/model_save/transfer_second_freeze_acc.pth')\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_history)\n",
    "plt.plot(valid_loss_history)\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "with open(\"valid_second_freeze.csv\", 'w') as file:\n",
    "  writer = csv.writer(file)\n",
    "  writer.writerow(valid_loss_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "with open(\"train_second_freeze.csv\", 'w') as file:\n",
    "  writer = csv.writer(file)\n",
    "  writer.writerow(train_loss_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5450759530067444\n",
      "Test Accuracy of the model on the 363 test images: 68.04407713498622 %\n"
     ]
    }
   ],
   "source": [
    "true_label=[]\n",
    "pred_label=[]\n",
    "\n",
    "model=LiverResnet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyper_param_learning_rate)\n",
    "\n",
    "checkpoint = torch.load('/home/sumins/workspace/washout classification/model_save/transfer_second_freeze.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "print(loss)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for item in test_loader:\n",
    "        npys = item['npy'].to(device)\n",
    "        labels = item['label'].to(device)\n",
    "        \n",
    "        outputs =model(npys)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        true_label.extend(labels)\n",
    "        pred_label.extend(predicted)\n",
    "        total += len(labels)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('Test Accuracy of the model on the {} test images: {} %'.format(total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.03      0.05       103\n",
      "           1       0.71      0.94      0.81       260\n",
      "\n",
      "    accuracy                           0.68       363\n",
      "   macro avg       0.43      0.48      0.43       363\n",
      "weighted avg       0.55      0.68      0.59       363\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "true_labels=torch.tensor(true_label)\n",
    "true_labels=true_labels.tolist()\n",
    "pred_labels=torch.tensor(pred_label)\n",
    "pred_labels=pred_labels.tolist()\n",
    "print(classification_report(true_labels,pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
